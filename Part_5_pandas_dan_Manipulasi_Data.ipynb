{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "A28b3tB976dH"
      ],
      "mount_file_id": "https://github.com/rikrikrahadian/DQLab/blob/main/Part_5_pandas_dan_Manipulasi_Data.ipynb",
      "authorship_tag": "ABX9TyOR9GW+dm1XO8zNkgZt7j5Z"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# *DATA MANIPULATION* IN PYTHON: `pandas`\n",
        "> ***Data Manipulation*** merujuk kepada proses penyesuaian (*adjustments*) yang dilakukan terhadap data agar lebih terorganisir dan mudah dibaca.\n",
        "\n",
        "Dalam sebuah organisasi yang mengedepankan pengambilan keputusan berbasis data, maka ***Data Manipulation*** adalah sebuah proses penting yang harus dilakukan terhadap beragam data yang dimanfaatkan olehnya. Proses tersebut akan memastikan bahwa berbagai `datasets` yang tersedia selaras dengan kebutuhan organisasi, serta memiliki format dan struktur yang konsisten, sehingga meningkatkan efisiensi pada pelaksanaan berbagai proses penting seperti:\n",
        "1. Pembacaan data;\n",
        "2. Analisis data;\n",
        "3. Interpretasi data; dan\n",
        "4. Proyeksi data.\n",
        "\n",
        "Python adalah salah satu ***Data Manipulation Languange*** (**DML**) yang paling populer dipergunakan oleh para *data scientists*, *data analysts*, peneliti dan akademisi. Popularitas Python tersebut tak lepas dari tersedianya sebuah modul/library bernama `pandas`, yang menyediakan berbagai *toolkits* yang sangat handal untuk dimanfaatkan melakukan *handling* dan *manipulating* data yang terstruktur.\n",
        "\n",
        "Pertemuan kesepuluh ini secara khusus ditujukan untuk membahas pemanfaatan modul `pandas` untuk kegiatan manipulasi data yang dimulai dengan proses *parsing* serta pemanfaatan *attributes* dan *methods* untuk deskripsi, seleksi, pengolahan, dan *serialization* data.\n"
      ],
      "metadata": {
        "id": "x2H3DgcRUgJi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Parsing data into `Pandas Dataframe` Object\n",
        "> `Pandas Dataframe` adalah sebuah `objek` Python berstruktur data dua dimensional berupa `rows` dan `columns` yang masing-masingnya memiliki label unik.\n",
        "\n",
        "Sesuai dengan deskripsi di atas, secara visual, sebuah `Pandas Dataframe` memiliki struktur tabular. Serupa dengan tabel SQL pada sebuah *database*, atau sebuah *spreadsheet* pada sebuah file excel. Pada sebuah `pandas.dataframe`, terdapat dua elemen berupa:\n",
        "1. `columns`, yang masing-masingnya merupakan objek satu dimensional--`pandas.series`--dan memiliki nomor/nama indeks yang unik.\n",
        "> Objek `pandas.series` memiliki karakteristik hampir serupa dengan sebuah `list` yang berisikan banyak elemen yang homogen, akan tetapi sebuah `pandas.series` memiliki cara indexing yang jauh lebih fleksibel dibandingkan `python fundamental objects`.\n",
        "2. `rows`, yang merepresentasikan catatan data (*records*) dan berkarakter satu dimensional--`pandas.series`--yang masing-masing elemennya harus diberikan indeks (berupa nama kolom) yang unik.\n",
        "> `rows` memiliki karakteristik serupa dengan sebuah `dictionary` yang berisikan *paired-element* berupa `key` = `str` berupa nama kolom, dan `value` = `list` dengan elemen berupa data yang tersimpan pada kolom tersebut.\n",
        "\n",
        "Pada pertemuan sebelumnya, secara sekilas telah diperkenalkan beberapa `methods` dari `pandas` yang umumnya dipergunakan untuk tujuan konstruksi `pandas.dataframe` object. Beberapa methods tersebut antara lain:\n",
        "- `pandas.DataFrame()`, untuk mengkonversi berbagai objek python--`list`, `tuple`, dan `dictionary`--menjadi sebuah `pandas.dataframe`;\n",
        "- `pandas.join()`, untuk menggabungkan dua `pandas.dataframe` dengan memanfaatkan index saling terkait; dan\n",
        "- `pandas.concat()`, untuk menggabungkan beberapa `pandas.dataframe` berdasarkan axisnya.\n",
        "\n",
        "Kali ini kita akan memfokuskan praktel pada konstruksi `pandas.dataframe` object melalui proses *parsing* data dari berbagai jenis file data. Berikut ini adalah beberapa method yang umum dipergunakan:\n",
        "- [`pandas.read_csv()`](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html), untuk parsing data pada file berekstensi `.csv` dan `.txt` ke sebuah `pandas.dataframe`;\n",
        "- [`pandas.read_json()`](https://pandas.pydata.org/docs/reference/api/pandas.read_json.html), untuk parsing data pada file berekstensi `.json` ke sebuah `pandas.dataframe`;\n",
        "- [`pandas.read_excel()`](https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html), untuk parsing data pada file berekstensi `.xls` dan `.xlsx` ke sebuah `pandas.dataframe`; dan\n",
        "- [`pandas.ExcelFile()`](https://pandas.pydata.org/docs/reference/api/pandas.ExcelFile.html), untuk parsing data pada file berekstensi `.xls`, `xlsx`, `xlsm`, `xlsb`, `odt`, `odf`, dan `ods`."
      ],
      "metadata": {
        "id": "D9B8SwlGgD3T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ilustrasi 1: `.csv` Data Parsing\n",
        "\n",
        "Lakukan *data parsing* dari sebuah file `.csv` yang disimpan di: 'https://storage.googleapis.com/dqlab-dataset/SuperStore.csv'."
      ],
      "metadata": {
        "id": "13vj-1FJ2Ylv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengimpor modul pandas ke environment\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "m0nIdZjDMRr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign lokasi file ke `file_path`\n",
        "file_path ='https://storage.googleapis.com/dqlab-dataset/SuperStore.csv'"
      ],
      "metadata": {
        "id": "wzsB8B7aUzMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parse dataset pada file di atas ke `df_superstore`\n",
        "\n",
        "# tampilkan hasis parsing tersebut\n"
      ],
      "metadata": {
        "id": "e8sPbxyyXiNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pada prakteknya, tidak semua kolom yang tersedia akan dipergunakan dalam proses pengolahan, sehingga melakukan parsing data secara keseluruhan akan menjadi tidak efisien---selain akan memerlukan lebih banyak memory sebagai penyimpanan, juga akan memakan waktu jika data yang diparsing cukup banyak.\n",
        "\n",
        "Pada ilustrasi ini, kita akan memanfaatkan berbagai parameter pada method `pd.read_csv` untuk melakukan parsing secara efisien."
      ],
      "metadata": {
        "id": "Xc1SjelVWOm0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parsing hanya 10 rows pertama saja\n",
        "df_superstore_10 = pd.read_csv(file_path, nrows=10)\n",
        "# Tunjukkan isi dataframe dari memory\n",
        "df_superstore_10"
      ],
      "metadata": {
        "id": "6CaFRkUEWgDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parsing seluruh rows untuk kolom `State`, `Quantity`, dan `Sales`\n",
        "df_superstore_kolom = pd.read_csv(file_path, usecols=['State', 'Quantity', 'Sales'])\n",
        "# Tunjukkan isi dataframe dari memory\n",
        "df_superstore_kolom"
      ],
      "metadata": {
        "id": "qOGeGKmXXIYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ilustrasi 2: Mounting Google Drive\n",
        "Salah satu kelebihan dari `Google Colab Notebook` adalah integrasi dengan `Google Drive`, sehingga data yang tersimpan di `Google Drive` dapat dimanipulasi dengan menggunakan `Google Colab`. Untuk dapat memanfaatkan fasilitas tersebut, maka user harus:\n",
        "1. Memiliki google account dan terlogin.\n",
        "2. Menambahkan [shared folder](https://drive.google.com/drive/folders/1yCSH4zq7khyfQ0w8C6NOQGxrgdEhhd5r?usp=sharing) ke google drivenya dengan cara:\n",
        "  - Buka link shared folder tersebut;\n",
        "  - Menekan `Dataset/Use Case Harian` > `Organize` > `Add Shortcut`; dan\n",
        "  - Pilih directory penyimpanan, lalu tekan `Add`.\n",
        "3. Buka `File Explorer` pada Google Colab Notebook, lalu tekan `Mount Drive`,\n",
        "\n"
      ],
      "metadata": {
        "id": "VaWxacXAjAz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengimpor method glob dari modul glob\n",
        "from glob import glob"
      ],
      "metadata": {
        "id": "PJ3XAkO2kIos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set folder tempat file sesuai dengan lokasi di Google Drive masing-masing\n",
        "folder_file = '/content/drive/MyDrive/DQLab/data_for_dqlab/Dataset Use Case Harian/' # ini harus disesuaikan dengan lokasi di masing-masing google drive\n",
        "# Set tipe file yang akan kita parse\n",
        "file_pattern = 'STATISTIK*.xlsx'"
      ],
      "metadata": {
        "id": "9cCjPQNpju2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Buat list nama-nama file yang ditemukan\n",
        "list_xlsx = glob(folder_file+file_pattern)\n",
        "# lihat isi list\n",
        "list_xlsx"
      ],
      "metadata": {
        "id": "lzgI42tnkO6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ilustrasi 3: Excel file data parsing\n",
        "Melakukan parsing file excel dengan menggunakan method `pd.read_excel`."
      ],
      "metadata": {
        "id": "KIvlWkiAq_0A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parsing 5 rows paling atas pada file excel\n",
        "pd.read_excel(list_xlsx[0], nrows=5)"
      ],
      "metadata": {
        "id": "fk-GLUbUkqGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parsing 5 rows paling atas, tanpa menyertakan baris judul\n",
        "pd.read_excel(list_xlsx[0], nrows=5, skiprows=1)"
      ],
      "metadata": {
        "id": "6tZaSz_YIdqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parsing 5 rows paling atas, tanpa judul, dan membuat 2 baris pertama sebagai header\n",
        "pd.read_excel(list_xlsx[0], nrows=5, skiprows=1, header=[0, 1])"
      ],
      "metadata": {
        "id": "b5TwGgORI3dg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parsing 5 rows paling atas, tanpa judul, 2 baris pertama sebagai header, dan 4 kolom pertama sebagai index\n",
        "pd.read_excel(list_xlsx[0], nrows=5, skiprows=1, header=[0, 1], index_col=[0, 1, 2, 3])"
      ],
      "metadata": {
        "id": "oLRubfkkJISQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parsing 5 rows paling atas, tanpa judul, 2 baris pertama sebagai header, 4 kolom pertama sebagai index,\n",
        "# mereset index, dan menghapus rows bernilai 'NaN'\n",
        "pd.read_excel(list_xlsx[0], nrows=5, skiprows=1, header=[0, 1], index_col=[0, 1, 2, 3]).reset_index().dropna(axis=0)"
      ],
      "metadata": {
        "id": "PGtcvgK9JiKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ilustrasi 4: Excel file data parsing\n",
        "Melakukan parsing file excel menggunakan method `pd.ExcelFile`."
      ],
      "metadata": {
        "id": "8Z8Eqw_zrkXy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parsing isi file\n",
        "xl = pd.ExcelFile(list_xlsx[0])\n",
        "# Tunjukkan isi hasil parsing\n",
        "xl"
      ],
      "metadata": {
        "id": "Z-12iFWSs2sn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Melakukan pengecekan nama-nama sheet pada file\n",
        "xl.sheet_names"
      ],
      "metadata": {
        "id": "-LwJCgRVtK42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parsing seluruh isi dataset ke dataframe\n",
        "xl.parse(xl.sheet_names[0], skiprows=1, header=[0,1], index_col=[0, 1, 2, 3]).reset_index().dropna(axis=0)"
      ],
      "metadata": {
        "id": "LSnMEdNXtZAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perhatikan `dataframe` hasil parsing tersebut:\n",
        "1. Apa perbedaan fungsi `pd.read_excel` dengan `pd.ExcelFile`?\n",
        "1. Jenis tabel apakah `dataframe` tersebut di atas? Longform atau Wideform??\n",
        "2. Sudahkah `dataframe` tersebut tergolong `tidy data`?"
      ],
      "metadata": {
        "id": "tfI4DsAa7gA4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EXERCISE 1: Data Parsing\n",
        "Pada exercise 1 ini, kita akan berlatih untuk menkonversi dataframe dengan wide form menjadi long form."
      ],
      "metadata": {
        "id": "_cghl2qbugtx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Menampilkan 5 rows paling atas pada 'TABEL 561' assign ke variabel df\n"
      ],
      "metadata": {
        "id": "gwZWEXPFMJkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# KONVERSI dataframe 'TABEL 561' MENJADI TIDY DATA, menggunakan method pd.melt()\n",
        "# MERAPIKAN NAMA KOLOM, DAN MENAMBAH DATA NAMA TABEL DAN TAHUN KE dataframe\n",
        "# ASSIGN HASILNYA KE df_561_melted\n"
      ],
      "metadata": {
        "id": "S8p3agei8erk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# KONVERSI KE TIDY DATA BAGI KE TABEL-TABEL LAINNYA\n",
        "# LALU MENGGABUNGKAN SELURUH dataframes KE SATU dataframe\n",
        "# TAMBAHKAN DATA NAMA TABEL, DAN TAHUN\n"
      ],
      "metadata": {
        "id": "la8tTfmx-bjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MEMBUAT FUNGSI BAGI PEMROSESAN DIATAS\n",
        "# UNTUK REPLIKASI PROSES KE DATA TAHUN BERIKUTNYA\n",
        "\n",
        "def parsing_statistik_indonesia(\n",
        "    file_path: str,\n",
        "    tahun: int\n",
        "  ) -> pd.DataFrame:\n",
        "  \"\"\"\n",
        "  Fungsi untuk melakukan parsing seluruh dataset pada file STATISTIK INDONESIA\n",
        "  ke sebuah dataframe.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  1. file_path: object string berisikan informasi path ke file dimaksud;\n",
        "  2. tahun: object integer berisikan informasi tahun yang akan diparsing.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  Sebuah pandas dataframe berisikan dataset yang telah diparsing.\n",
        "  \"\"\"\n",
        "  # 1. Parsing seluruh isi File Excel\n",
        "  xl = pd.ExcelFile(file_path)\n",
        "  # 2. Bikin list kosong\n",
        "  list_of_dfs = list()\n",
        "  # 3. Proses parsing dan melting per sheet\n",
        "  for sheet in xl.sheet_names:\n",
        "    # Parsing dataset\n",
        "    df = xl.parse(sheet, skiprows=1, header=[0,1], index_col=[0, 1, 2, 3]).reset_index().dropna(axis=0)\n",
        "    # Melting dataframe ke longform\n",
        "    df_melted = pd.melt(df, id_vars=df.columns[:4].to_list()).set_axis(['kode_provinsi', 'provinsi', 'kode_kabupaten', 'kabupaten_kota', 'variabel', 'satuan', 'nilai'], axis=1)\n",
        "    # Tambah data nama sheet\n",
        "    df_melted['tabel'] = sheet\n",
        "    # Tambah Data tahun\n",
        "    df_melted['tahun'] = tahun\n",
        "    # Append dataframe ke list\n",
        "    list_of_dfs.append(df_melted)\n",
        "\n",
        "  # 4. Gabungkan seluruh dataframe sebagai output fungsi\n",
        "  return pd.concat(list_of_dfs, axis=0, ignore_index=True)"
      ],
      "metadata": {
        "id": "yOca5N0rDzEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parse file SI 2019\n"
      ],
      "metadata": {
        "id": "7pnY23LxF4KB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parse file SI 2020\n"
      ],
      "metadata": {
        "id": "00bdGs4kG7tk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parse seluruh file SI pada folder ke sebuah dataframe\n"
      ],
      "metadata": {
        "id": "_W_Z1zorHDlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## *Data Description*\n",
        "> `Attributes` VS `Methods`\n",
        "> - `Attributes` adalah berbagai karakteristik yang terdapat pada sebuah objek;\n",
        "> - `Methods` adalah berbagai fungsi yang dapat diterapkan kepada sebuah objek.\n",
        "\n",
        "Oleh karena pada prinsipnya `pandas.dataframe` adalah sebuah objek python, maka sudah barang tentu ia akan memiliki `attributes` dan juga `methods`. Dua ilustrasi pada bagian ini akan mencontohkan bagaimana penerapan baik `attributes` maupun `methods` dari `pandas.dataframe` dalam proses mendeskripsikan data."
      ],
      "metadata": {
        "id": "A28b3tB976dH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ilustrasi 5: `pandas.dataframe` attributes\n",
        "Eksekusi beberapa attributes di bawah berikut, lalu tuliskan jawaban beberapa pertanyaan di bawah ini pada `markdown cell` yang disediakan:\n",
        "- Apa perbedaan dari `pd.dataframe.ndim`, `pd.dataframe.shape`, dan `pd.dataframe.size`?\n",
        "- Attribute apa yang kita pergunakan untuk mengetahui berbagai indeks dan sekaligus nama kolom yang ada pada sebuah dataframe?\n",
        "- Attribute apa yang kita pergunakan untuk mengetahui informasi tipe data dari masing-masing kolom pada sebuah dataframe?"
      ],
      "metadata": {
        "id": "Q43acR_9-mkc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_superstore.ndim"
      ],
      "metadata": {
        "id": "jLGLnwd9-N2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_superstore['Sales'].ndim"
      ],
      "metadata": {
        "id": "beX3OpW-87QB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_superstore.shape"
      ],
      "metadata": {
        "id": "LJMR5RYr9DR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_superstore.size"
      ],
      "metadata": {
        "id": "pwH3GhVl-Cu4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_superstore.columns"
      ],
      "metadata": {
        "id": "0A4frWLEMf67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_superstore.index"
      ],
      "metadata": {
        "id": "Cd_0h2FBM2Y4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_superstore.axes"
      ],
      "metadata": {
        "id": "osymVVgK9lHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_superstore.dtypes"
      ],
      "metadata": {
        "id": "lbXV0pjV9J09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_superstore.values"
      ],
      "metadata": {
        "id": "Nc3ogoOdNNSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ilustrasi 6: `pandas.dataframe`'s methods\n",
        "Eksekusi beberapa `cell codes` di bawah berikut, lalu tuliskan jawaban beberapa pertanyaan berikut ini di `markdown cell` yang disediakan:\n",
        "1. Apa perbedaan antara method `pd.dataframe.head()` dengan `pd.dataframe.tail()`?\n",
        "2. Apa perbedaan antara method `pd.dataframe.info()` dengan `pd.dataframe.describe()`?\n",
        "3. Opsi apa saja yang dapat dijadikan `argument` bagi parameter `include` pada method `pd.dataframe.describe()`?\n",
        "4. Berapa nilai rata-rata dari kolom `Sales`?\n",
        "5. Nilai apa yang menjadi `modus` dari kolom `Category`?"
      ],
      "metadata": {
        "id": "fk2NnPaXGcbq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_superstore.head(10)"
      ],
      "metadata": {
        "id": "gOuxFMxTHHHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_superstore.tail()"
      ],
      "metadata": {
        "id": "-32dMqtcHM2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_superstore.info()"
      ],
      "metadata": {
        "id": "8XXMvdtKGzNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_superstore.describe()"
      ],
      "metadata": {
        "id": "tr4uQ_Q4G2MO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_superstore.describe(include='number')"
      ],
      "metadata": {
        "id": "aFBp1oeeG5ZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_superstore.describe(include='object')"
      ],
      "metadata": {
        "id": "lw2WWbuUJZI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_superstore.describe(include='all')"
      ],
      "metadata": {
        "id": "KQX88_egBIF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_superstore.nlargest(5, 'Profit')"
      ],
      "metadata": {
        "id": "nbILG2gAn7gY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_superstore.nsmallest(5, 'Profit')"
      ],
      "metadata": {
        "id": "UKZo897xpaso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ilustrasi 7: `pandas.series`'s methods\n",
        "Eksekusi setiap `code cell` di bawah berikut, lalu lengkapi informasi terkait masing-masing method pada `code cell` terkait."
      ],
      "metadata": {
        "id": "ic01KMX3meCl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Method `pd.series.value_counts` adalah untuk\n",
        "df_superstore['Sub-Category'].value_counts()"
      ],
      "metadata": {
        "id": "0rCryGDNlmMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Method `pd.series.min` adalah untuk ...\n",
        "df_superstore['Sales'].min()"
      ],
      "metadata": {
        "id": "FDm8Q72Sni_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Method `pd.series.max` adalah untuk ...\n",
        "df_superstore['Sales'].max()"
      ],
      "metadata": {
        "id": "muVmFFRsnnNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Method `pd.series.sum` adalah untuk ...\n",
        "df_superstore['Sales'].sum()"
      ],
      "metadata": {
        "id": "_-vI7dAVl93U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Method `pd.series.mean` adalah untuk ...\n",
        "df_superstore['Sales'].mean()"
      ],
      "metadata": {
        "id": "Hbuwq410mC1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Method `pd.series.std` adalah untuk ...\n",
        "df_superstore['Sales'].std()"
      ],
      "metadata": {
        "id": "zqGYKKg-nXs4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Method `pd.series.median` adalah untuk ...\n",
        "df_superstore['Sales'].median()"
      ],
      "metadata": {
        "id": "06aRMbJ7nLi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Method `pd.series.quantile(0.25)` adalah untuk ...\n",
        "df_superstore['Sales'].quantile(0.25)"
      ],
      "metadata": {
        "id": "dmKqckXzm3l5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Method `pd.series.quantile(0.5)` adalah untuk ...\n",
        "df_superstore['Sales'].quantile(0.5)"
      ],
      "metadata": {
        "id": "G5CIC1tcnEkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Method `pd.series.quantile(0.75)` adalah untuk ...\n",
        "df_superstore['Sales'].quantile(0.75)"
      ],
      "metadata": {
        "id": "np1i_-XTnSzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## *Data Selection*\n",
        "Salah satu keunggulan utama `pandas` dalam melakukan manipulasi data adalah kemudahan dalam melakukan pemilihan data. Pada prinsipnya pemilihan data dapat dilakukan dengan menggunakan teknik *slicing* seperti telah dicontohkan pada ilustrasi sebelumnya, akan tetapi cara tersebut dirasa kurang *elegan* dan seringkali sulit untuk dimengerti.\n",
        "\n",
        "Pada bagian ini akan disampaikan tatacara pemilihan data yang biasanya dilakukan dalam `pandas`, dimulai dengan pengenalan terhadap `accessors` untuk pemilihan data, hingga penyusunan `filter`."
      ],
      "metadata": {
        "id": "OMM8KU6cjPq8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Accessors\n",
        "> `Accessors` adalah objek yang disematkan ke sebuah `attribute` dari `pandas.dataframe/pandas.series` yang memberikan fungsionalitas ekstra tertentu.\n",
        "\n",
        "`pandas` menyediakan dua `accessors` yang sangat populer dipergunakan untuk melakukan pemilihan data secara fleksibel, antara lain:\n",
        "1. `pd.dataframe.loc[]`, dengan format penggunaan:\n",
        "```\n",
        "nama_dataframe.loc[<pilih_rows>, <pilih_nama_kolom>]\n",
        "```\n",
        "2. `pd.dataframe.iloc[]`, dengan format penggunaan:\n",
        "```\n",
        "nama_dataframe.iloc[<pilih_rows>, <pilih_indeks_kolom>]\n",
        "```"
      ],
      "metadata": {
        "id": "eCuhcerBjogV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ilustrasi 8: Pemilihan Data - `Accessors`\n",
        "Tuliskan beberapa perbedaan utama baik dalam cara penggunaan maupun output dari `accessor` `.loc` dengan `.iloc`, di `markdown cell` yang disediakan di bawah, setelah `kedua `code cell` di bawah berikut di eksekusi."
      ],
      "metadata": {
        "id": "6VxRLX97uZj8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_superstore.loc[df_superstore['Profit']<0, ['Order_ID', 'Category', 'Sub-Category', 'Sales', 'Profit']]"
      ],
      "metadata": {
        "id": "FWBxwFhsueus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_superstore.iloc[[3, 14, 15, 23], [0, 8, 9, 4, 7]]"
      ],
      "metadata": {
        "id": "eKoaV8Pdu73a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_superstore.loc[0:10, ['Order_ID', 'Category', 'Sub-Category', 'Sales', 'Profit']]"
      ],
      "metadata": {
        "id": "ycEFTH45Ps57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_superstore.iloc[0:10, [0, 8, 9, 4, 7]]"
      ],
      "metadata": {
        "id": "P95kX0p3P-hV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PERBEDAAN `loc` vs `iloc`:**\n",
        "\n",
        "1.\n"
      ],
      "metadata": {
        "id": "1eYzjimYdUuZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Filtering\n",
        "Salah satu fitur lain yang disediakan `pandas` adalah memanfaatkan `boolean arrays` untuk melakukan filtering. Filtering dilakukan melalui dua tahap berikut, yaitu:\n",
        "1. Menyusun filter, dengan format penulisan umumnya:\n",
        "```python\n",
        "nama_filter = <boolean_expression>\n",
        "```\n",
        "2. Menyematkan filter ke dataframe, dengan format penulisan:\n",
        "```python\n",
        "data_difilter = nama_dataframe[nama_filter]\n",
        "```"
      ],
      "metadata": {
        "id": "PdtAmAUwju9E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ilustrasi 9: Data Filtering\n",
        "Scripts di bawah ini ditujukan untuk menghasilkan dataframe berisikan `rows` dengan nilai `Profit` negatif (mengalami kerugian) dari `df_superstore` yang sebelumnya sudah kita *parse*."
      ],
      "metadata": {
        "id": "a67lhwLmxWKF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_superstore[['Order_ID', 'Category', 'Sub-Category', 'Sales', 'Profit']]"
      ],
      "metadata": {
        "id": "RxlXWk-QQUiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat filter bagi row yang mengalami kerugian (profit<0)\n",
        "filter_sales_rugi = df_superstore['Profit']<0\n",
        "\n",
        "# Menyematkan filter ke dataframe induk, assign ke sales_merugi\n",
        "sales_merugi = df_superstore[filter_sales_rugi]\n",
        "# lihat isi sales_merugi\n",
        "sales_merugi"
      ],
      "metadata": {
        "id": "zttfIErzxeCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Querying\n",
        "\n",
        "Selain kedua cara yang telah disebutkan sebelumnya di atas, `pandas` juga menyediakan sebuah method yang memungkinkan dilakukannya filtering dengan gaya query pada `SQL`. Terdapat dua method yang disedakan oleh `pandas`, yaitu:\n",
        "1. `pd.DataFrame.query` yang dipergunakan untuk melakukan filtering rows berdasarkan kondisi tertentu, dengan contoh penggunaan method tersebut:\n",
        "```python\n",
        "data_difilter = nama_dataframe.query(\"suatu_kolom == 1\")\n",
        "```\n",
        "2. `pd.DataFrame.filter` yang dipergunakan untuk melakukan filtering terhadap index pada dataframe, baik kolom maupun rows, dengan contoh penggunaan sebagai berikut:\n",
        "```python\n",
        "data_difilter_kolom = nama_dataframe.filter(<list_nama_kolom>, axis=1)\n",
        "data_difilter_row = nama_dataframe.filter(<list_index_row>, axis=0)\n",
        "```"
      ],
      "metadata": {
        "id": "IQWjIE9PjLxE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ilustrasi 10: Querying\n",
        "Lengkapi ekspresi pada statements di bawah, agar dapat dieksekusi untuk menghasilkan dataframe berisikan `rows` dengan nilai `Profit` negatif (mengalami kerugian) dari `df_superstore` yang sebelumnya sudah kita *parse*."
      ],
      "metadata": {
        "id": "EcwInxiMk3Ce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Terapkan method query untuk memfilter rows dengan nilai Profit<0\n",
        "sales_merugi_query = df_superstore.query('Profit<0')\n",
        "\n",
        "# lihat isi sales_merugi_query\n",
        "sales_merugi_query"
      ],
      "metadata": {
        "id": "vM6qzLS1kM_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Terapkan method filter untuk menampilkan kolom-kolom tertentu saja dari sales_merugi_query\n",
        "sales_merugi_query.filter(['Order_ID', 'Category', 'Sub-Category', 'Sales', 'Profit'])"
      ],
      "metadata": {
        "id": "c4wgsnBiqaxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_superstore.query('Segment==\"Consumer\"')"
      ],
      "metadata": {
        "id": "6E2fQG7yRsbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EXERCISE 2\n",
        "Melakukan pemilihan data menggunakan:\n",
        "1. Tiga filter:\n",
        "  - `rows` dimana value `Sales` melebihi nilai quantile ke-3nya;\n",
        "  - `rows` dimana value `Region` adalah 'East'; dan\n",
        "  - `rows` dimana value `Profit` melebihi nilai quantile ke-3nya.\n",
        "2. Kolom-kolom terpilih:\n",
        "```python\n",
        "['Order_ID', 'Category', 'Sub-Category', 'Sales', 'Profit', 'Region']\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "HbplVv8DyIqI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FILTERING : ACCESSOR .loc\n",
        "# Buat filters\n",
        "filter_sales_over =\n",
        "filter_region =\n",
        "filter_profit =\n",
        "\n",
        "# Buat kolom pilihan:\n",
        "kolom_terpilih =\n",
        "\n",
        "# Pilih data, gunakan accessor `.loc`\n",
        "sales_tinggi_east =\n",
        "\n",
        "# Cek isi sales_tinggi\n",
        "sales_tinggi_east"
      ],
      "metadata": {
        "id": "VzQYnqhlyP6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# QUERYING\n",
        "# Buat query bagi filtering\n",
        "query_filter = f\"Region=='East' & Sales>{df_superstore['Sales'].quantile(0.75)} & Profit>{df_superstore['Profit'].quantile(0.75)}\"\n",
        "\n",
        "# gunakan method `pd.dataframe.query` & `pd.dataframe.filter` untuk melakukan filtering\n",
        "sales_tinggi_east_query =\n",
        "\n",
        "# lihat isi sales_tinggi query\n",
        "sales_tinggi_east_query"
      ],
      "metadata": {
        "id": "odzO0CYpGijB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Data Sorting\n",
        "Mengurutkan data berdasarkan value pada kolom tertentu dapat dengan mudah dilakukan dengan menggunakan method `pandas.dataframe.sort_values()`, dengan format penulisan seperti berikut:\n",
        "```python\n",
        "nama_dataframe.sort_values(by=<list_nama_kolom>, ascending=<list_boolean>]\n",
        "```"
      ],
      "metadata": {
        "id": "yV5L0gaa0qU3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ilustrasi 11: Sorting data\n",
        "1. Lakukan pengurutan data `sales_merugi` berdasarkan kriteria berikut:\n",
        " - Value `Profit` dari yang paling rendah;\n",
        " - Value `Sales` dari yang paling tinggi.\n",
        "2. Lakukan pengurutan data `sales_tinggi` berdasarkan kriteria berikut:\n",
        " - Value `Profit` dari yang paling tinggi;\n",
        " - Value `Sales` dari yang paling tinggi."
      ],
      "metadata": {
        "id": "_0J5mL7O4aP8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sales_merugi.sort_values(by=['Profit', 'Sales'], ascending=[True,False])[['Profit', 'Sales']]"
      ],
      "metadata": {
        "id": "tfRd0Fn03g62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sales_tinggi_east.sort_values(by=['Profit', 'Sales'], ascending=[False,False])"
      ],
      "metadata": {
        "id": "L8DxgHTS5eca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## *Data Manipulation*"
      ],
      "metadata": {
        "id": "XTl6PGehkdwR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *Arithmatic Operations*\n",
        "Berbagai operasi aritmatik--penjumlahann(`+`), pengurangan (`-`), pembagian (`/`), perkalian (`*`), dan pemangkatan (`**`)--dapat diterapkan terhadap `pandas.series` dan `pandas.dataframe` objek.\n",
        "Format penulisan operasi aritmatika, antara lain:\n",
        "```python\n",
        "# Operasi aritmatika antar kolom\n",
        "dataframe[<nama_kolom_baru>] = dataframe[<kolom_a>] <operator_aritmatika> dataframe[<kolom_b>]\n",
        "```"
      ],
      "metadata": {
        "id": "cIEDeYtI_uJY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ilustrasi 12: Menghitung Harga Satuan\n",
        "Dataframe `df_superstore` yang sebelumnya telah kita parse ternyata tidak memiliki informasi terkait harga satuan dari masing-masing `Sales` yang terjadi. Oleh karena informasi tersebut diperlukan, maka kita perlu untuk melakukan penghitungan harga satuan, dan menyimpan hasil perhitungan tersebut pada sebuah kolom baru bernama `Price`.\n",
        "\n",
        "Sebelum menuliskan `script` untuk perhitungan diatas, lengkapi beberapa informasi yang diperlukan berikut:\n",
        "- Data yang akan diperlukan untuk menghitung `Price` adalah:\n",
        "  - ```Sales```\n",
        "  - ```Quantity```\n",
        "- Rumus penghitungan `Price` adalah:\n",
        "\n",
        "  $ Price_i = \\frac{Sales_i}{Quantity_i} $"
      ],
      "metadata": {
        "id": "hYQ8e12ACyDO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Menghitung Harga Satuan\n",
        "df_superstore['Price'] = df_superstore['Sales']/df_superstore['Quantity']"
      ],
      "metadata": {
        "id": "LmgfewgZBEzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_superstore.head()"
      ],
      "metadata": {
        "id": "NkOyJzrhJgnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EXERCISE 3\n",
        "*Management* memerlukan informasi terkait 10 Transaksi Penjualan yang memiliki persentase nilai penjualan yang paling tinggi untuk tujuan pemberian reward. Lakukan penghitungan persentase sales dari total sales, dan simpan hasilnya pada kolom baru bernama `Share`.\n",
        "\n",
        "Sama seperti pada **Ilustrasi 9** sebelumnya, silahkan tuliskan beberapa informasi yang diperlukan di bawah ini:\n",
        "- Data yang diperlukan:\n",
        "  - ```Sales```\n",
        "  - ```Total_Sales```\n",
        "- Rumus perhitungan:\n",
        "\n",
        "  $ Share_{i} = \\frac{Sales_i}{\\sum Sales}*100 $"
      ],
      "metadata": {
        "id": "ccYcqRY3Op1C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hitung Share\n",
        "df_superstore['Share'] =\n",
        "# Tampilkan 10 rows dengan Share Sales paling besar\n"
      ],
      "metadata": {
        "id": "1sjls9UrOzka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_superstore.head()"
      ],
      "metadata": {
        "id": "kZtjbEukX0Fr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *Applying Functions to `DataFrame`*\n",
        "`Pandas` menyediakan beberapa methods yang dapat mengakomodir berbagai proses manipulasi data pada objek `pandas.dataframe` dan `pandas.series` dengan menggunakan `functions`, `methods` atau bahkan `user-defined functions` secara berantai (`method chaining`), antara lain:\n",
        "1. `.apply()`, dengan format penulisan:\n",
        "```python\n",
        "# Memanipulasi data dengan menerapkan function ke seluruh kolom pada DataFrame:\n",
        "dataframe.apply(func, axis: [0, 1]=0)\n",
        "# Memanipulasi data dengan enerapkan function ke sebuah kolom tertentu pada DataFrame:\n",
        "dataframe[<nama_kolom>].apply(func)\n",
        "```\n",
        "2. `.assign()`, dengan format penulisan:\n",
        "```python\n",
        "# Memanipulasi data pada pada suatu kolom menggunakan method dan menyimpan hasilnya di kolom baru\n",
        "dataframe.assign(nama_kolom_baru=lambda df: df[<nama_kolom>].method())\n",
        "```\n",
        "3. `.pipe()`, dengan format penulisan:\n",
        "```python\n",
        "# Memanipulasi dataframe menggunakan fungsi user-defined\n",
        "dataframe.pipe(<nama_fungsi_userdefined>, parameter=argument)\n",
        "```"
      ],
      "metadata": {
        "id": "1z-K6gVm_92p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "#### *Lambda Function* di Python\n",
        "Salah satu tipe fungsi yang akan sering dipergunakan ketika melakukan pengolahan data menggunakan python adalah `lambda function`.\n",
        "\n",
        "> *Lambda function* adalah sebuah fungsi *generic* yang biasanya berstruktur sederhana, dibuat secara cepat dan ringkas **tanpa perlu mendefinisikan fungsi secara lengkap** dengan `def`.\n",
        "\n",
        "##### Struktur Umum:\n",
        "\n",
        "```python\n",
        "lambda parameter: <ekspresi>\n",
        "```\n",
        "\n",
        "##### `User-defined function` VS `lambda function`:\n",
        "\n",
        "```python\n",
        "# User-defined function biasa\n",
        "def pangkat_2(x):\n",
        "    return x ** 2\n",
        "\n",
        "# Lambda function setara\n",
        "pangkat_2_lambda = lambda x: x ** 2\n",
        "\n",
        "print(pangkat_2_lambda(5))  # Output: 25\n",
        "```\n",
        "\n",
        "##### Kapan Menggunakan Lambda?\n",
        "\n",
        "Lambda biasa digunakan saat kita butuh fungsi **sekilas**, terutama di dalam:\n",
        "\n",
        "* fungsi seperti `map()`, `filter()`, `sorted()`, dll.\n",
        "* konteks pemrograman fungsional atau cepat-cek\n",
        "\n",
        "##### Contoh:\n",
        "\n",
        "```python\n",
        "# Menyaring angka genap dari list\n",
        "angka = [1, 2, 3, 4, 5, 6]\n",
        "genap = list(filter(lambda x: x % 2 == 0, angka))\n",
        "print(genap)  # Output: [2, 4, 6]\n",
        "\n",
        "# Mengurutkan daftar berdasarkan panjang string\n",
        "kata = ['apel', 'jeruk', 'kiwi']\n",
        "sorted_kata = sorted(kata, key=lambda x: len(x))\n",
        "print(sorted_kata)  # Output: ['kiwi', 'apel', 'jeruk']\n",
        "```\n",
        "\n",
        "##### Catatan:\n",
        "\n",
        "* Lambda hanya bisa berisi **satu ekspresi**, tidak bisa berisi banyak pernyataan.\n",
        "* Gunakan untuk **fungsi sederhana** saja agar kode tetap mudah dibaca.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "UXv4mlPoFq7K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ilustrasi 13: Memanipulasi Data `String`\n",
        "Pada ilustrasi 13 ini, akan dilakukan manipulasi data `string` pada kolom `Customer_Name` sebagai berikut:\n",
        "1. Dirubah menjadi upper case; dan\n",
        "2. Dirubah menjadi lower case;\n",
        "\n",
        "Masing-masing proses tersebut akan dilakukan dengan menggunakan method `.apply()` dan `.assign()`."
      ],
      "metadata": {
        "id": "-s1n25MwRm7F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tampilkan 5 record teratas pada Series df_superstore['Customer_Name']\n",
        "df_superstore['Customer_Name'].head()"
      ],
      "metadata": {
        "id": "phAP7YUyawH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merubah value Customer_Name ke upper case menggunakan method .apply()\n",
        "df_superstore['Customer_Name'].apply(lambda x: x.upper()).head()"
      ],
      "metadata": {
        "id": "iSDrfXOREdi7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merubah value Customer_Name ke lower case menggunakan method .apply()\n",
        "df_superstore['Customer_Name'].apply(lambda elemen: elemen.lower()).head()"
      ],
      "metadata": {
        "id": "SfcjzPUksG0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cek lima rows paling atas pada df_superstore\n",
        "df_superstore.head()"
      ],
      "metadata": {
        "id": "HgriQcQbgAAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# merubah Value Customer_Name ke upper case menggunakan method .assign()\n",
        "df_superstore.assign(Customer_Name=lambda df: df['Customer_Name'].str.upper()).head()"
      ],
      "metadata": {
        "id": "5gB-b4jtsZO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merubah Value Customer_Name ke lower case menggunakan method .assign()\n",
        "df_superstore.assign(Customer_Name=lambda df: df['Customer_Name'].str.lower()).head()"
      ],
      "metadata": {
        "id": "EH64yrreqaX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cek lima rows paling atas pada df_superstore\n",
        "df_superstore.head()"
      ],
      "metadata": {
        "id": "PTvrO571uprW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ilustrasi 14: Manipulasi Data `String`\n",
        "Pada ilustrasi ini, kita akan mencoba untuk melakukan manipulasi value pada Customer_Name berupa proses pemisahan menjadi 2 berdasarkan karakter `space` yang pertama ditemukan, lalu menyimpan hasilnya ke kolom `First_Name` dan `Last_Name`. Proses dimaksud akan dilakukan dengan menggunakan method `.pipe()` dan `.assign()`."
      ],
      "metadata": {
        "id": "2dfncnI8tD46"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# User-defined function\n",
        "def split_string(\n",
        "    df: pd.DataFrame,\n",
        "    nama_kolom: str,\n",
        "    list_kolom_baru: list,\n",
        "    pattern: str = \" \",\n",
        "    jumlah_split: int = 1,\n",
        "    inplace: bool = False) -> pd.DataFrame | None:\n",
        "    \"\"\"\n",
        "    Fungsi untuk memecah value bertipe str pada sebuah kolom,\n",
        "    lalu menyimpan hasilnya ke dua kolom baru\n",
        "    Arguments:\n",
        "       1. df: dataframe yang salah satu kolomnya akan displit;\n",
        "       2. nama_kolom: Nama kolom yang valuenya akan displit;\n",
        "       3. list_kolom_baru: List berisi dua nama kolom baru untuk menyimpan hasil split;\n",
        "       4. pattern: Pola string yang dijadikan patokan bagi proses split;\n",
        "       5. jumlah_split: Jumlah proses pemisahan yang dilakukan terhadap sebuah elemen;\n",
        "       6. inplace: Proses pemisahan langsung dilakukan terhadap df atau tidak.\n",
        "    \"\"\"\n",
        "    # Validasi jumlah elemen list_kolom_baru\n",
        "    if len(list_kolom_baru) != jumlah_split+1:\n",
        "        raise ValueError('Jumlah elemen pada list_kolom_baru tidak sesuai dengan jumlah_split')\n",
        "\n",
        "    # Split Strings lalu simpan di kolom baru\n",
        "    if inplace == True:\n",
        "        df[list_kolom_baru] = df[nama_kolom].str.split(pat=pattern, n=jumlah_split, expand=True)\n",
        "        return df\n",
        "    else:\n",
        "        df_copy = df.copy()\n",
        "        df_copy[list_kolom_baru] = df_copy[nama_kolom].str.split(pat=pattern, n=jumlah_split, expand=True)\n",
        "        return df_copy"
      ],
      "metadata": {
        "id": "_wfPy6uHrU5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menanggil split_string untuk mengolah df_superstore\n",
        "split_string(df_superstore, 'Customer_Name', ['Fist_Name', 'Last_Name']).head()"
      ],
      "metadata": {
        "id": "6bfHdyno-RX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat kolom First_Name dan Last_Name menggunakan method .pipe()\n",
        "df_superstore.pipe(split_string, nama_kolom='Customer_Name', list_kolom_baru=['First_Name', 'Last_Name'])"
      ],
      "metadata": {
        "id": "ghYtbLTzAj6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat kolom First_Name dan Last_Name menggunakan method .assign()\n",
        "df_superstore.assign(First_Name=lambda df: df['Customer_Name'].str.split(pat=' ', n=1, expand=True)[0],\n",
        "                     Last_Name=lambda df: df['Customer_Name'].str.split(pat=' ', n=1, expand=True)[1]).head()"
      ],
      "metadata": {
        "id": "fRvc8JfbtWqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tampilkan 5 rows teratas dari df_superstore\n",
        "df_superstore.head()"
      ],
      "metadata": {
        "id": "205DReFxuT6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *Method Chaining* di Python\n",
        "\n",
        "> *Method chaining* adalah teknik pemrograman di mana **beberapa method dipanggil secara berurutan pada sebuah objek**, dalam satu baris kode.\n",
        "\n",
        "##### Mengapa Digunakan?\n",
        "\n",
        "* Membuat kode lebih **ringkas** dan **terbaca seperti alur proses**.\n",
        "* Menghindari penulisan berulang variabel antara satu proses dengan proses berikutnya.\n",
        "\n",
        "##### Contoh pada *String*:\n",
        "\n",
        "```python\n",
        "kalimat = \"  belajar Python itu MUDAH  \"\n",
        "hasil = kalimat.strip().lower().replace(\"mudah\", \"menyenangkan\")\n",
        "print(hasil)  # Output: belajar python itu menyenangkan\n",
        "```\n",
        "\n",
        "Penjelasan:\n",
        "\n",
        "1. `.strip()` menghapus spasi di awal dan akhir\n",
        "2. `.lower()` mengubah semua huruf jadi kecil\n",
        "3. `.replace()` mengganti kata\n",
        "\n",
        "##### Contoh pada *pandas DataFrame*:\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# Contoh DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'Nama': ['Ari', 'Budi', 'Citra', 'Dina'],\n",
        "    'Nilai': [80, 55, 90, 65]\n",
        "})\n",
        "\n",
        "# Chaining untuk filter dan sort\n",
        "hasil = df[df['Nilai'] > 60].sort_values(by='Nilai', ascending=False).reset_index(drop=True)\n",
        "\n",
        "print(hasil)\n",
        "```\n",
        "\n",
        " Penjelasan:\n",
        "\n",
        "1. `df[df['Nilai'] > 60]`  menyaring baris dengan nilai > 60\n",
        "2. `.sort_values()`  mengurutkan dari nilai tertinggi\n",
        "3. `.reset_index()`  mereset indeks setelah sortir\n",
        "\n",
        "##### Tips:\n",
        "\n",
        "* Pastikan setiap method **mengembalikan objek baru** (bukan `None`), agar chaining bisa berlanjut.\n",
        "* Jika terlalu panjang, gunakan pemenggalan dengan menggunakan tanda `\\` atau pindahkan ke beberapa baris untuk keterbacaan.\n",
        "\n",
        "```python\n",
        "# Contoh tanpa pemenggalan\n",
        "kalimat.strip().lower().replace('mudah', 'menyenangkan')\n",
        "\n",
        "# Contoh pemenggalan \\\n",
        "kalimat \\\n",
        ".strip() \\\n",
        ".lower() \\\n",
        ".replace('mudah', 'menyenangkan')\n",
        "\n",
        "# Contoh pemenggalan baris\n",
        "(\n",
        "  kalimat\n",
        "  .strip()\n",
        "  .lower()\n",
        "  .replace('mudah', 'menyenangkan')\n",
        ")\n",
        "```\n",
        "---"
      ],
      "metadata": {
        "id": "fiyYfcC8E16f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ilustrasi 15: Manipulasi Data String: `Method Chaining`"
      ],
      "metadata": {
        "id": "mqqY9AI9unFm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Melakukan manipulasi secara method Chaining\n",
        "(\n",
        "    pd.read_csv(file_path, usecols=['Customer_Name'])\n",
        "    .assign(Customer_Capitalized=lambda df: df['Customer_Name'].str.upper(),\n",
        "            Customer_Lower_Case=lambda df: df['Customer_Name'].str.lower())\n",
        "    .pipe(split_string, nama_kolom='Customer_Name', list_kolom_baru=['First_Name', 'Last_Name'])\n",
        ").head()"
      ],
      "metadata": {
        "id": "CU0rMC_TA2VF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_nama_dimanipulasi = (\n",
        "    pd.read_csv(file_path, usecols=['Customer_Name'])\n",
        "    .assign(Customer_Capitalized=lambda df: df['Customer_Name'].str.upper(),\n",
        "            Customer_Lower_Case=lambda df: df['Customer_Name'].str.lower(),\n",
        "            First_Name=lambda df: df['Customer_Name'].str.split(pat=' ', n=1, expand=True)[0],\n",
        "            Last_Name=lambda df: df['Customer_Name'].str.split(pat=' ', n=1, expand=True)[1])\n",
        "    .filter(['Customer_Name', 'First_Name', 'Last_Name', 'Customer_Capitalized', 'Customer_Lower_Case'])\n",
        ")\n",
        "df_nama_dimanipulasi.head()"
      ],
      "metadata": {
        "id": "KzPRVNrOBUbO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *Grouping and Aggregation*\n",
        "Secara sederhana, proses mengaggregatkan sekelompok value, seperti yang dimuat dalam sebuah `pandas.series` dapat dilakukan dengan menggunakan beberapa method seperti berikut:\n",
        "1. `.sum()`;\n",
        "2. `.count()`;\n",
        "3. `.mean()`;\n",
        "4. `.median()`;\n",
        "5. `.min()`;\n",
        "6. `.max()`; dan\n",
        "7. `.std()`.\n",
        "\n",
        "Namun pada prakteknya, aggregasi akan jauh lebih bermanfaat jika dilakukan berdasarkan pengelompokkan atau pelabelan tertentu. Untuk melakukan aggregasi dengan pengelompokkan, maka `pandas` menyediakan method `.groupby()` yang dapat dikombinasikan langsung dengan `aggregate methods` di atas, dengan format penulisan seperti berikut ini:\n",
        "```python\n",
        "# Aggregasi dengan grouping sederhana\n",
        "dataframe.groupby([<kolom_kolom_pengelompokkan>])[kolom_dihitung].method()\n",
        "```\n",
        "Tak jarang diperlukan beberapa aggregasi yang dilakukan sekaligus terhadap beberapa values, berdasarkan pengelompokkan tertentu. `Pandas` juga menyediakan fitur yang memungkinkan dilakukannya kebutuhan seperti tersebut, melalui method `.agg()`, dengan format penulisan sebagai berikut:\n",
        "```python\n",
        "# Multiple Aggregation\n",
        "dataframe.groupby([<kolom_kolom_pengelompokkan>]).agg({\n",
        "  'kolom_dihitung_1':[fungsi_fungsi_aggregat],\n",
        "  'kolom_dihitung_2':[fungsi_fungsi_aggregat]\n",
        "})\n",
        "```"
      ],
      "metadata": {
        "id": "rD2hgD0S_oUN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ilustrasi 16: Grouping and Aggregation\n",
        "Beberapa pertanyaan yang biasanya ditanyakan adalah sebagai berikut:\n",
        "1. Negara bagian mana yang memiliki rata-rata Sales paling tinggi?\n",
        "2. Negara bagian mana yang memiliki total Profit paling rendah?\n",
        "\n",
        "Pada ilustrasi ini, kedua pertanyaan tersebut akan dijawab dengan menggunakan method aggregasi sederhana, dan method `.agg()`."
      ],
      "metadata": {
        "id": "BIZ5cATG4Zl0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Aggregasi Sederhana Rata-rata Sales per Negara Bagian\n",
        "df_superstore.groupby(['State'])['Sales'].mean().sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "Bb4RnbKr1GJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aggregasi Sederhana Total Profit per Negara Bagian\n",
        "df_superstore.groupby(['State'])['Profit'].sum().sort_values()"
      ],
      "metadata": {
        "id": "p9-hA2Uv7eQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aggregasi Total dan Rata-rata Sales dan Profit per Negara Bagian\n",
        "(df_superstore\n",
        " .groupby(['State'])\n",
        " .agg({'Sales':['mean', 'sum'], 'Profit':['sum']})\n",
        " .rename(columns={'sum':'Total', 'mean':'Rataan'})\n",
        " .sort_values(by=[('Profit', 'Total')], ascending=True)\n",
        " )"
      ],
      "metadata": {
        "id": "WbRcinuBVRDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EXERCISE 4: Aggregation\n",
        "1. Lakukan aggregasi data df_superstore berdasarkan `Category` dan `Sub-Category`;\n",
        "2. Hitung Total, Jumlah, dan Rata-rata dari `Sales`;\n",
        "3. Gunakan method `.assign()` untuk menghitung persentase `Sales` dari Total `Sales` untuk masing-masing `row`, simpan ke kolom baru bernama `Sales_Share`;\n",
        "4. Simpan hasil pengolahan ke variabel `sales_by_cat`."
      ],
      "metadata": {
        "id": "V345sAoO6jVV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k0L1sx5whr5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o6G1dgtui9nW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *Pivot Table*\n",
        "Salah satu fitur penting yang disediakan `pandas` untuk melakukan data manipulation adalah fungsi `pandas.pivot_table()`. Pada dasarnya fungsi ini menghasilkan output yang hampir serupa dengan proses `Grouping and Aggregation` seperti dijelaskan sebelumnya. Format penulisan bagi fungsi ini adalah sebagai berikut:\n",
        "```python\n",
        "pd.pivot_table(df,\n",
        "  index=[kolom_kolom_grouping],\n",
        "  values=kolom_dihitung,\n",
        "  columns=[kolom_kolom_pemilah_values],\n",
        "  aggfunc=[fungsi_fungsi_aggregasi]\n",
        ")\n",
        "```"
      ],
      "metadata": {
        "id": "5e_uisrf4Ks1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ilustrasi 17: `pd.pivot_table`\n",
        "Melakukan Aggregasi Total, Jumlah, dan Rata-rata dari `Sales` per `Region`, yang dikelompokkan berdasarkan `Category` dan `Sub-Category` dari produk menggunakan fungsi `pd.pivot_table()`. Lengkapi ekspresi yang tidak lengkap pada statement di bawah ini, lalu eksekusi untuk melihat hasilnya."
      ],
      "metadata": {
        "id": "HT5vc_JrCeFm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pivoted = pd.pivot_table(\n",
        "    data=pd.read_csv(file_path, usecols=['Category', 'Segment', 'Sales', 'Region']),\n",
        "    index=['Category', 'Segment'],\n",
        "    columns='Region',\n",
        "    values='Sales',\n",
        "    aggfunc=['sum', 'count', 'mean'],\n",
        "    margins=True,\n",
        "    margins_name='All'\n",
        ").rename(columns={'sum':'Total', 'count':'Jumlah', 'mean':'Rataan'})\n",
        "\n",
        "df_pivoted"
      ],
      "metadata": {
        "id": "H5tLdpFlwCvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Slicing Multiple Index\n",
        "df_pivoted[[('Jumlah')]]"
      ],
      "metadata": {
        "id": "qchlhLJyMSXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ilustrasi 18: Rata-rata Pertumbuhan Tahunan TTC\n",
        "Salah satu komoditas **`Perikanan Tangkap`** unggulan Indonesia yang memiliki pasar ekspor cukup besar adalah kelompok ikan **Tuna, Tongkol, dan Cakalang** (**TTC**). Pada ilustrasi ini akan dilakukan proses manipulasi data yang terdapat pada dataset di dalam file `DATA PERIKANAN.xlsx`, untuk menghasilkan informasi **`rata-rata pertumbuhan produksi komoditas TTC sepanjang periode 2018 - 2023`**. Adapun langkah-langkah pengerjaan yang dilakukan adalah sebagai berikut:\n",
        "1. Data parsing:\n",
        "    - sheet_name: `TANGKAP`;\n",
        "    - usecols: `['provinsi', 'kelompok_ikan', 'tahun', 'produksi_ton']`;\n",
        "    - Lalu lakukan filtering berdasarkan kriteria:\n",
        "        1. kelompok_ikan in `['TUNA', 'TONGKOL', 'CAKALANG']`;\n",
        "        2. tahun >= 2018\n",
        "2. Buat pivot table yang menunjukkan nilai **`total produksi antar tahun`** dengan pasangan `parameter=argument` sebagai berikut:\n",
        "    - index: `provinsi`;\n",
        "    - columns: `tahun`;\n",
        "    - values: `produksi_ton`;\n",
        "    - aggfunc: `sum`\n",
        "3. Hapus rows yang berisi nilai kosong (`NaN`);\n",
        "4. Hitung Pertumbuhan Produksi antar tahun;\n",
        "5. Hitung rata-rata Pertumbuhan Produksi antar tahun; dan\n",
        "6. Mengurutkan rows berdasarkan rata-rata Pertumbuhan Produksi antar tahun."
      ],
      "metadata": {
        "id": "UWwVphKGOCoo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import modul os\n",
        "import os\n",
        "\n",
        "# set file path\n",
        "file_name = \"DATA PERIKANAN.xlsx\"\n",
        "file_path_perikanan = os.path.join(folder_file, file_name)\n",
        "\n",
        "# Pastikan file path benar ada\n",
        "os.path.exists(file_path_perikanan)"
      ],
      "metadata": {
        "id": "9ucX6ymzVXc1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Melakukan Data parsing\n",
        "ttc_2018 = (\n",
        "    pd.ExcelFile(file_path_perikanan)\n",
        "    .parse(sheet_name='TANGKAP', usecols=['provinsi', 'kelompok_ikan', 'tahun', 'produksi_ton'])\n",
        "    .query('kelompok_ikan in [\"TUNA\", \"TONGKOL\", \"CAKALANG\"] & tahun>=2018')\n",
        ")\n",
        "\n",
        "ttc_2018"
      ],
      "metadata": {
        "id": "xDixoN2Xcphv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Menyiapkan DataFrame agar siap dihitung pertumbuhan\n",
        "ttc_pivoted = pd.pivot_table(\n",
        "    ttc_2018,\n",
        "    index='provinsi',\n",
        "    columns='tahun',\n",
        "    values='produksi_ton',\n",
        "    aggfunc='sum').dropna()\n",
        "\n",
        "ttc_pivoted"
      ],
      "metadata": {
        "id": "zmVvQvYCctmI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Menghitung Pertumbuhan produksi TTC pertahun dan Rata-ratanya\n",
        "pertumbuhan_by_provinsi = ((ttc_pivoted\n",
        " .pct_change(axis='columns', fill_method=None)*100)\n",
        " .assign(average_growth = lambda df: round(df.mean(axis='columns'), 2))\n",
        " .sort_values('average_growth', ascending=False)\n",
        " .dropna(axis=1))\n",
        "\n",
        "pertumbuhan_by_provinsi"
      ],
      "metadata": {
        "id": "SHNDw-IZdSsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## *Serialization*\n",
        "\n",
        "> *Serialization* adalah proses konversi sebuah objek ke dalam format yang memudahkan proses **penyimpanan ke file**, **pengiriman melalui jaringan**, atau **pertukaran data antar program**.\n",
        "\n",
        "Dalam konteks Python dan analisis data, serialization sangat berguna ketika kita ingin:\n",
        "\n",
        "* Menyimpan hasil *data processing* agar bisa digunakan kembali tanpa harus mengulang proses yang memakan waktu.\n",
        "* Membagikan objek Python (seperti *DataFrame*) ke sistem lain.\n",
        "* Melakukan *checkpointing* saat training model atau pipeline analisis.\n",
        "\n",
        "### `pickle`  Modul Bawaan Python untuk Serialization\n",
        "\n",
        "Python menyediakan modul built-in bernama `pickle` untuk melakukan serialization dan deserialization objek Python ke format biner.\n",
        "\n",
        "#### Contoh:\n",
        "\n",
        "```python\n",
        "import pickle\n",
        "\n",
        "data = {'nama': 'Ali', 'umur': 30}\n",
        "\n",
        "# Simpan (serialize)\n",
        "with open('data.pkl', 'wb') as file:\n",
        "    pickle.dump(data, file)\n",
        "\n",
        "# Buka kembali (deserialize)\n",
        "with open('data.pkl', 'rb') as file:\n",
        "    data_loaded = pickle.load(file)\n",
        "\n",
        "print(data_loaded)\n",
        "```\n",
        "\n",
        "> `pickle` cocok untuk menyimpan objek Python apa pun  dictionary, list, model machine learning, atau bahkan DataFrame.\n",
        "\n",
        "---\n",
        "\n",
        "###  Serialization Khusus untuk `pandas.DataFrame`\n",
        "\n",
        "Modul `pandas` menyediakan berbagai metode serialization yang memungkinkan pengguna menyimpan `DataFrame` ke berbagai format **tekstual**, **biner**, maupun **terstruktur**.\n",
        "\n",
        "Berikut beberapa format umum yang didukung:\n",
        "\n",
        "#### 1. CSV dan TXT\n",
        "\n",
        "Format paling umum dan ringan untuk penyimpanan tabel.\n",
        "\n",
        "```python\n",
        "df.to_csv('data.csv')     # Simpan ke CSV\n",
        "df.to_csv('data.txt')     # Bisa juga ke .txt\n",
        "```\n",
        "\n",
        "#### 2. JSON\n",
        "\n",
        "Cocok untuk pertukaran data berbasis web atau API.\n",
        "\n",
        "```python\n",
        "df.to_json('data.json')\n",
        "```\n",
        "\n",
        "#### 3. Excel (`.xlsx` / `.xls`)\n",
        "\n",
        "Digunakan saat berbagi dengan pengguna non-programmer, atau untuk laporan.\n",
        "\n",
        "```python\n",
        "df.to_excel('data.xlsx', sheet_name='Sheet1')\n",
        "```\n",
        "\n",
        ">  Perlu install `openpyxl` atau `xlsxwriter` untuk menyimpan ke `.xlsx`.\n",
        "\n",
        "#### 4. Pickle\n",
        "\n",
        "Untuk menyimpan DataFrame lengkap dengan tipe data dan struktur internalnya.\n",
        "\n",
        "```python\n",
        "df.to_pickle('data.pkl')\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### Perbandingan Format\n",
        "\n",
        "| Format  | Kelebihan                          | Kekurangan                        |\n",
        "| ------- | ---------------------------------- | --------------------------------- |\n",
        "| `.csv`  | Ringan, umum, mudah dibaca manusia | Tidak simpan tipe data kompleks   |\n",
        "| `.json` | Fleksibel, cocok untuk web/API     | Lebih besar dari CSV, nested data |\n",
        "| `.xlsx` | Populer di kalangan non-programmer | Perlu library tambahan            |\n",
        "| `.pkl`  | Simpan struktur lengkap (lossless) | Tidak bisa dibuka di luar Python  |\n",
        "\n",
        "---\n",
        "\n",
        "### Deserialization: Membuka Kembali Data\n",
        "\n",
        "Contoh membuka file serialized:\n",
        "\n",
        "```python\n",
        "# Dari CSV\n",
        "pd.read_csv('data.csv')\n",
        "\n",
        "# Dari Excel\n",
        "pd.read_excel('data.xlsx')\n",
        "\n",
        "# Dari JSON\n",
        "pd.read_json('data.json')\n",
        "\n",
        "# Dari Pickle\n",
        "pd.read_pickle('data.pkl')\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### Catatan Keamanan\n",
        "\n",
        "> Hindari menggunakan `pickle.load()` terhadap file dari sumber tidak terpercaya. File `.pkl` bisa menjalankan kode berbahaya saat di-load.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "0peivq_T3BOC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ilustrasi 19: *Serialize* hasil manipulasi data ke format `.csv`\n",
        "Serialize `pertumbuhan_by_provinsi` ke file `csv` bernama `Olahan_Data_Perikanan.csv`."
      ],
      "metadata": {
        "id": "w58WFNNgqKNS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Serialize to csv\n",
        "(pertumbuhan_by_provinsi\n",
        " .to_csv('Olahan_Data_Perikanan.csv', index=False))"
      ],
      "metadata": {
        "id": "VVekfoeRqapi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ilustrasi 20: Serialize to `.xlsx`\n",
        "Pada ilustrasi ini, kita akan melakukan serialization dataframe `pertumbuhan_by_provinsi` yang sudah kita hasilkan pada ilustrasi terdahulu ke dalam sebuah file berformat `xlsx` bernama `Olahan_Data_Perikanan.xlsx` ke sheet bernama `GROWTH BY PROV`."
      ],
      "metadata": {
        "id": "umNwBLw0C601"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Serialize `pertumbuhan_by_provisi` ke file Excel\n",
        "(pertumbuhan_by_provinsi\n",
        " .to_excel('Olahan_Data_Perikanan.xlsx', sheet_name='GROWTH BY PROV'))"
      ],
      "metadata": {
        "id": "AQE1wC9JEOi0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EXERCISE 5: Appending new sheet to `xlsx`\n",
        "Pada Exercise ini, akan dilakukan penghitungan `Rata-Rata` `Pertumbuhan Produksi Perikanan Budidaya Indonesia`, untuk `kelompok_ikan` bernilai `NILA` dan `NILEM`, pada periode 2018 - 2023, lalu melakukan serializing hasilnya ke file `xlsx` yang sama dengan sumber data pada sheet baru bernama `GROWTH NILEM`."
      ],
      "metadata": {
        "id": "9bZs8s-loJb9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hitung pertumbuhan nilem\n",
        "growth_nilem = ((pd.pivot_table(\n",
        "    pd.ExcelFile(file_path_perikanan)\n",
        "    .parse(sheet_name='BUDIDAYA', usecols=['provinsi', 'kelompok_ikan', 'tahun', 'produksi_ton'])\n",
        "    .query('kelompok_ikan in [\"NILA\", \"NILEM\"] & tahun>=2018'),\n",
        "    index='provinsi',\n",
        "    columns='tahun',\n",
        "    values='produksi_ton',\n",
        "    aggfunc='sum'\n",
        ").pct_change(axis='columns', fill_method=None)*100)\n",
        ".assign(average_growth = lambda df: round(df.mean(axis='columns'), 2))\n",
        ".sort_values('average_growth', ascending=False)\n",
        ".dropna(axis=1))"
      ],
      "metadata": {
        "id": "TptXQMRdIbgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Buat `ExcelWriter` object dengan mode `append` assign ke variabel `writer`\n",
        "with pd.ExcelWriter('Olahan_Data_Perikanan.xlsx', mode='a') as writer:\n",
        "  # Serialize growth_nilem ke sheet 'GROWTH NILEM'\n",
        "  growth_nilem.to_excel(writer, sheet_name='GROWTH NILEM')"
      ],
      "metadata": {
        "id": "wjRwAo_POo7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check apakah data sudah masuk file excel\n",
        "pd.read_excel('Olahan_Data_Perikanan.xlsx', sheet_name='GROWTH NILEM')"
      ],
      "metadata": {
        "id": "ljBMLtNML-oT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "___"
      ],
      "metadata": {
        "id": "RoszpILWWAWf"
      }
    }
  ]
}