{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ***DATA HANDLING***\n",
        "Pada pertemuan kesebelas ini, akan disampaikan materi terkait *Data Handling* -- mulai dari proses parsing, manipulasi, dan pengolahan agar dapat dihasilkan sebuah dataframe yang siap dianalisis lebih lanjut untuk memperoleh *insights*. Dalam latihan kali ini, kita akan menggunakan salah satu dataset dari koleksi datasets yang disediakan oleh **R** secara gratis pada [Link](https://vincentarelbundock.github.io/Rdatasets/datasets.html) berikut.\n",
        "\n",
        "Meskipun pada pertemuan terdahulu, telah disampaikan materi terkait manipulasi data beserta prakteknya, pada kenyataannya, seringkali manipulasi data tidak dapat segera dilakukan akibat dari kondisi dataset yang kita peroleh belum siap untuk diolah lebih lanjut. Oleh karena itu, *data handling* menjadi sebuah proses yang sangat penting dan penguasaan seorang data analyst terhadapnya menjadi sebuah prasyarat penting.\n",
        "\n",
        "Proses *data handling* mensyaratkan penguasaan beragam teknik pengolahan data yang meliputi teknik-teknik mulai dari parsing data, manipulasi kolom data, pembuatan ringkasan statistik, visualisasi data, hingga ke pemahaman pola yang muncul dalam data. Tingkat kesulitan dari proses ini akan sangat tergantung pada kondisi dataset yang tersedia. Dataset yang tergolong sudah rapi cenderung akan mudah untuk di-*handle*, sebaliknya *dataset* yang 'berantakan' akan membutuhkan waktu *handling* yang jauh lebih panjang. Oleh karena itu, paparan terhadap berbagai jenis data set dari bermacam sumber akan meningkatkan kemahiran data analis dalam melakukan *data handling*.  \n",
        "\n",
        "Meskipun sebenarnya sudah diperkenalkan secara sekilas pada pertemuan-pertemuan terdahulu, pertemuan ini secara khusus difokuskan ke pemanfaatan modul **pandas** dalam **Python** sebagai alat untuk melakukan *data handling*, melalui kegiatan praktek langsung. Pada praktek kali ini, berbagai `functions` dan `methods`, baik yang telah disampaikan pada pertemuan-pertemuan sebelumnya maupun yang baru akan diterapkan terhadap dataset `Titanic.csv` untuk menghasilkan sebuah dataset yang rapi hingga siap dipergunakan sebagai bahan analisis lebih lanjut. Untuk membantu memahami berbagai teknik yang diterapkan, maka pada hampir setiap proses akan disertakan juga **TECHNICAL NOTE** yang merupakan penjelasan ringkas dari teknik yang diterapkan.\n",
        "\n",
        "## ***Dataset Titanic***\n",
        "> Dataset Titanic berisikan informasi rinci tentang penumpang yang berada di kapal **MS. Titanic**, yang tenggelam pada 15 April 1912 setelah bertabrakan dengan gunung es, dan merupakan salah satu dataset yang paling populer digunakan dalam *data science* terutama untuk materi klasifikasi.\n",
        "\n",
        "Salah satu jenis analisis yang paling umum dilakukan menggunakan dataset Titanic adalah melakukan *Survival Analysis* yang melibatkan pembangunan model *Machine Learning* untuk memprediksi kelangsungan hidup penumpang berdasarkan karakteristiknya. Fitur seperti jenis kelamin dan kelas memiliki dampak signifikan terhadap tingkat kelangsungan hidup seorang penumpang. Sebagai ilustrasi, wanita dan anak-anak akan memiliki peluang hidup yang lebih tinggi dibanding kelompok lain, karena adanya protokol evakuasi yang mendahulukan kedua kelompok tersebut. Selain itu penumpang di kelas yang lebih tinggi (1st) memiliki peluang selamat yang lebih besar dibandingkan dengan mereka yang menumpang di kelas lebih rendah (2nd dan 3rd)."
      ],
      "metadata": {
        "id": "6me1P9nt8NtU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Di dalam modul **pandas** tersedia beberapa *tools* untuk melakukan data handling, seperti:\n",
        "\n",
        "1. **Membaca Data**:\n",
        "   - [`pd.read_csv()`](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html): Untuk membaca file CSV.\n",
        "   - [`pd.read_json()`](https://pandas.pydata.org/docs/reference/api/pandas.read_json.html): Untuk parsing data JSON.\n",
        "   - [`pd.read_excel()`](https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html): Untuk membaca data dari file Excel.\n",
        "   - [`pd.read_sql()`](https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html): Untuk membaca query SQL ke dalam DataFrame.\n",
        "   \n",
        "2. **Pembersihan Data**: Setelah parsing, data sering kali perlu dibersihkan, seperti menangani nilai yang hilang, memformat string, atau menghapus duplikat. Beberapa `methods` yang sangat berguna dalam proses ini antara lain:\n",
        "   - [`df.fillna()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.fillna.html): untuk mengisi data `NaN` dengan value tertentu secara serentak;\n",
        "   - [`df.dropna()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html): untuk menghapus rows/columns yang mengandung `NaN`; dan\n",
        "   - [`df.replace()`](): untuk menggantikan suatu value dengan value yang ditentukan.\n",
        "\n",
        "3. **Parsing String**: `Access Method` `str` yang tersedia pada pandas memungkinkan manipulasi dan parsing data teks, sehingga lebih mudah mengekstrak informasi dari string menggunakan beberapa method seperti:\n",
        "   1. `df.str.split()`;\n",
        "   2. `df.str.contains()`; dan\n",
        "   3. `df.str.extract()` untuk parsing berbasis regular expression.\n",
        "\n",
        "4. **Parsing Tanggal**: Fungsi `pd.to_datetime()` dapat memparsing string tanggal dalam berbagai format ke objek datetime yang sesuai untuk pengolahan. Fungsi ini akan berperan penting ketika bekerja dengan data deret waktu."
      ],
      "metadata": {
        "id": "qzWjI7N6A-7u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EXERCISE 1: *Data Parsing*\n",
        "Data parsing mengacu pada proses ekstraksi, interpretasi, dan transformasi data dari satu format ke format lain, sehingga siap untuk dianalisis. Dalam konteks **data science**, kemampuan melakukan parsing data yang berasal dari berbagai sumber, seperti CSV, JSON, XML, atau *database*, adalah salah satu keterampilan yang paling penting. Tujuan utama dari *parsing* adalah mengubah data mentah menjadi bentuk terstruktur, seperti **DataFrame** dalam **pandas**, yang siap digunakan untuk analisis.\n",
        "\n",
        "Pada EXERCISE ini, kita akan mencoba untuk memparsing data menggunakan library `pandas` dari sebuah file pada link berikut ini:\n",
        "  - https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Titanic.csv"
      ],
      "metadata": {
        "id": "JkJNdqoBec0Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I56iBBQl24rD"
      },
      "outputs": [],
      "source": [
        "# Import modul pandas\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set file path\n",
        "file_path_titanic =\n",
        "\n",
        "# Parse Data, set kolom 'rownames' sebagai index\n",
        "df_titanic ="
      ],
      "metadata": {
        "id": "zTGLSzkIbhIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pengecekan Awal\n",
        "\n",
        "*Preliminary Checking* adalah tahap perkenalan paling awal dengan dataset yang akan ditangani. Umumnya perkenalan terhadap dataset dimulai dengan menggali informasi terkait struktur, dan statistik deskriptif dari dataset. Dari hasil *preliminary checking* ini seorang data analis dapat menilai berbagai kekurangan dari dataset, sehingga memperoleh **perkiraan** awal proses apa saja yang perlu dilakukan untuk mempersiapkan data bagi analisis lebih lanjut.\n",
        "\n",
        "Pengenalan struktur dataset dilakukan dengan mencari informasi terkait dimensi dataset, seperti jumlah rows serta kolom yang terdapat pada dataset tersebut. Informasi penting lain yang biasanya diperoleh pada tahap ini adalah tipe data pada masing-masing kolom, berbagai pattern dari formatting data yang dikenakan, dan kelengkapan data setiap rows pada dataset.\n",
        "\n",
        "Sebagai pendalaman, pada tahap selanjutnya biasanya dilakukan analisis statistik deskriptif untuk memperoleh informasi sebaran dari data pada masing-masing kolom. Berbagai indikator yang dihasilkan dari analisis statistik desktiptif--semacam frekuensi, nilai minimum dan maksimum, rata-rata, median, kwartil pertama, kwartil ketiga, serta modus--dapat membantu kita untuk mengetahui kondisi dataset lebih mendalam."
      ],
      "metadata": {
        "id": "TxVpBFc0njKP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Struktur Dataset"
      ],
      "metadata": {
        "id": "5argy-cMz0xB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cek lima rows paling atas\n"
      ],
      "metadata": {
        "id": "xCxC6amV8A5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cek lima rows paling bawah\n"
      ],
      "metadata": {
        "id": "8s_yKpvk7mGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cek Struktur Data\n"
      ],
      "metadata": {
        "id": "cRYXRlcSBfv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "___\n",
        "**RESUME**: Struktur Dataset\n",
        "\n",
        "Tuliskan temuan dari proses pengecekan visual struktur data!\n",
        "1. Bagaimana format penulisan pada kolom `Name`?\n",
        "2. Apakah terdapat pattern tertentu pada penulisan data pada kolom `Name`?\n",
        "2. Adakah kolom yang dirasa tidak perlu?\n",
        "3. Bagaimana kelengkapan data masing-masing kolom?\n",
        "___"
      ],
      "metadata": {
        "id": "67_ZA3yu3rfW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Statistik Deskriptif"
      ],
      "metadata": {
        "id": "cuj8i8tlovmo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cek Statistik Deskriptif untuk kolom bertipe data numeric\n"
      ],
      "metadata": {
        "id": "LB-bmIgyBjfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cek Statistik Deskriptif untuk kolom bertipe data object\n"
      ],
      "metadata": {
        "id": "XNcGnIwNBmlb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "___\n",
        "**RESUME**: Statistik Deskriptif\n",
        "\n",
        "Tuliskan hasil temuan Analisis Deskriptif!!\n",
        "1. Adakah data penumpang yang terduplikasi?\n",
        "2. Berapa banyak data penumpang yang diduga terduplikasi?\n",
        "3. Berapa banyak kategori penumpang?.\n",
        "___"
      ],
      "metadata": {
        "id": "Sm1wpGbK4QrK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pengecekan Lanjutan\n",
        "*Follow up checking* adalah tahap dimana berbagai pertanyaan, dan dugaan terkait isi dari dataset dijawab, sehingga seorang data analis dapat menggali informasi lebih dalam dan jauh lebih mengenali dataset yang sedang ditangani.\n",
        "\n",
        "Beberapa temuan penting pada pengecekan terdahulu atas dataset pada dataframe `df_titanic` adalah sebagai berikut:\n",
        "1. Terdapat duplikasi data:\n",
        "  - Perlu diverifikasi apakah duplikasi Nama terjadi karena pencatatan terhadap objek yang sama;\n",
        "  - Perlu dicermati apakah terjadi duplikasi baris pada dataset.\n",
        "2. Terdapat *Missing Values*:\n",
        "  - Harus dicermati rows mana saja yang terdapat *missing values*;\n",
        "  - Harus dicermati seberapa banyak *missing values* yang ada;\n",
        "  - Harus diputuskan apa yang harus dilakukan terhadap *missing values* yang ada (dihapus, diisi) dan jika harus diisi, metode apa yang akan dipergunakan untuk mengisi.\n",
        "3. Terdapat *formatting* penulisan data pada kolom `Name` dan `PClass`, sehingga perlu dicermati keseragaman data pada kedua kolom tersebut."
      ],
      "metadata": {
        "id": "SoCDjChYt88u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Pengecekan Duplikasi\n",
        "Salah satu hal yang harus dipastikan ketika melakukan data handling adalah, **tidak ada rows yang terduplikasi**. Dalam hal ini, yang dimaksud dengan duplikasi adalah kejadian di mana sebuah transaksi tercatat secara berulang pada dataset. Rows yang terduplikasi harus dihilangkan dari dataset, karena dapat mengakibatkan bias pada hasil analisis.\n",
        "\n",
        "Modul `pandas` menyediakan method `duplicated` dan `drop_duplicates` untuk melakukan penanganan terhadap rows yang terduplikasi. Berikut ini adalah ilustrasi penggunaan method `duplicated` untuk mengamati dan menghilangkan rows yang terduplikasi:\n",
        "```python\n",
        "# MENGAMATI ROWS TERDUPLIKASI\n",
        "# 1. Buat filter untuk rows terduplikat\n",
        "filter_duplicated_first = dataframe.duplicated(keep='first')\n",
        "filter_duplicated_last = dataframe.duplicated(keep='last')\n",
        "filter_duplicated_False = dataframe.duplicated(keep=False)\n",
        "\n",
        "# 2. Sortir data menggunakan salah satu filter di atas\n",
        "dataframe.loc[filter_duplicated_first, :].sort_values(by=list(dataframe.columns))\n",
        "\n",
        "# MENGHILANGKAN ROWS TERDUPLIKASI\n",
        "# 1. Menghilangkan seluruh rows duplikasi selain rows duplikasi pertama\n",
        "dataframe.drop_duplicates(keep='first', inplace=True)\n",
        "\n",
        "# 2. Menghilangkan seluruh rows duplikasi selain rows duplikasi terakhir\n",
        "dataframe.drop_duplicates(keep='last', inplace=True)\n",
        "\n",
        "# 3. Menghilangkan seluruh rows duplikasi tanpa kecuali\n",
        "dataframe.drop_duplicates(keep=False, inplace=True)\n",
        "```\n",
        "___"
      ],
      "metadata": {
        "id": "TIxOQutyzPpe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ilustrasi 1: Handling Duplicated Rows"
      ],
      "metadata": {
        "id": "HYlxWvtEB1BV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Amir, Budi, Cici, dan Didi bermain lempar dadu sebanyak 6 ronde.\n",
        "Hasil setiap lemparan masing-masingnya dicatat pada dataframe df.\n",
        "Akan tetapi terjadi kesalahan pencatatan,\n",
        "sehingga terdapat dua ronde yang tercatatkan 2 kali.\n",
        "\"\"\"\n",
        "data = {\n",
        "  \"Amir\":[1, 2, 3, 4, 1, 1, 6, 4],\n",
        "  \"Budi\":[3, 1, 1, 1, 3, 4, 5, 1],\n",
        "  \"Cici\":[4, 4, 4, 4, 4, 4, 4, 4],\n",
        "  \"Didi\":[6, 6, 6, 6, 6, 6, 6, 6]\n",
        "}\n",
        "\n",
        "# Parse data menjadi sebuah dataframe\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Cek isi dataframe\n",
        "df"
      ],
      "metadata": {
        "id": "b9M2E-jG9-bU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cek duplicate jika \"keep='first'\"\n",
        "filter_duplicated_first = df.duplicated(keep='first')\n",
        "df.loc[filter_duplicated_first, :]"
      ],
      "metadata": {
        "id": "yu_suFMJ_TSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cek duplicate jika \"keep='last'\"\n",
        "filter_duplicated_last = df.duplicated(keep='last')\n",
        "df.loc[filter_duplicated_last, :]"
      ],
      "metadata": {
        "id": "WH6Wg-Ar_fMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cek duplicate jika \"keep=False\"\n",
        "filter_duplicated_false = df.duplicated(keep=False)\n",
        "df.loc[filter_duplicated_false, :].sort_values(by=list(df.columns))"
      ],
      "metadata": {
        "id": "WomPRRgA_l1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Buang seluruh duplikat kecuali data duplikat pertama\n",
        "df.drop_duplicates(keep='first')"
      ],
      "metadata": {
        "id": "YZ1AMPFY-unJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Buang seluruh duplikat kecuali duplikat terakhir\n",
        "df.drop_duplicates(keep='last')"
      ],
      "metadata": {
        "id": "MiE_oyCWAjBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Buang seluruh duplikat tanpa kecuali\n",
        "df.drop_duplicates(keep=False)"
      ],
      "metadata": {
        "id": "rK5i4dXWAq_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "___\n",
        "1. Duplicated Rows"
      ],
      "metadata": {
        "id": "85J571SnpqX9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Buat filter menggunakan method 'duplicated'\n",
        "filter_duplicated_rows = df_titanic.duplicated(keep=False)\n",
        "\n",
        "# Pergunakan filter_duplicated_rows untuk memfilter dataframe\n",
        "df_titanic.loc[filter_duplicated_rows, :]"
      ],
      "metadata": {
        "id": "b0BMk2fAps6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Duplicated `Name` Values"
      ],
      "metadata": {
        "id": "9i0kIYD9mAwy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Buat Filter menggunakan method 'duplicated'\n",
        "filter_duplicated_names = df_titanic.duplicated(subset='Name', keep=False)\n",
        "\n",
        "# Lakukan filtering dataframe menggunakan filter_duplicated_names\n",
        "df_titanic.loc[filter_duplicated_names, :]"
      ],
      "metadata": {
        "id": "PrsvQ2LvuxCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "___\n",
        "**RESUME**: *Duplications*\n",
        "\n",
        "Setelah melakukan pengamatan terhadap data terduplikasi, apa yang kira-kira harus dilakukan terhadap nama-nama yang terduplikasi?"
      ],
      "metadata": {
        "id": "RICHvOj99hzL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "___\n",
        "#### Mendeteksi *Missing Values*\n",
        "Modul `pandas` menotasikan *missing values* sebagai `NaN`, sebuah object bertipe `float`, yang sering kali diartikan sebagai *Not a Number*. Dalam bahasa pemrograman SQL, padanan dari `NaN` ini adalah `null`, yang merupakan indikasi tidak ada nilai yang tercatat untuk *field* tersebut.\n",
        "\n",
        "Seperti nilai `null`, `NaN` tidak dihitung dalam proses agregasi seperti `count` maupun `sum`, sehingga keberadaannya akan sangat mempengaruhi hasil dari analisis. Oleh karena itu, penanganan *missing values* merupakan salah satu proses yang sangat penting dalam *data handling*, terutama jika data akan digunakan dalam permodelan statistik atau *Machine Learning*. Ada beberapa pendekatan yang bisa diambil untuk menangani *missing values*, tergantung pada konteks dan tujuan analisis:\n",
        "\n",
        "1. Penghapusan (*Deletion*)<br>\n",
        "   **Jenis dan cara** penghapusan:\n",
        "   - **Penghapusan Kolom:** Jika sebuah kolom memiliki banyak *missing values*, lebih efisien untuk menghapus seluruh kolom tersebut, terutama jika variabel tersebut tidak relevan atau tidak memberikan kontribusi signifikan dalam analisis.\n",
        "   ```python\n",
        "   df.dropna(axis=1)\n",
        "   ```\n",
        "   - **Penghapusan Baris:** Jika hanya sebagian kecil baris yang mengandung *missing values*, kita dapat mempertimbangkan untuk menghapus baris-baris tersebut. Penghapusan baris umum dilakukan jika data yang hilang bersifat acak dan tidak berjumlah besar.\n",
        "   ```python\n",
        "   df.dropna(axis=0)\n",
        "   ```\n",
        "\n",
        "  **Kapan Melakukan Deletion**: <br>\n",
        "  *Deletion* lebih tepat digunakan jika jumlah *missing values* relatif sedikit, atau saat data yang hilang tidak memiliki signifikansi bagi analisis.\n",
        "\n",
        "2. Pengisian Nilai (*Imputation*)<br>\n",
        "   Pengisian nilai adalah alternatif lain yang sering kali lebih baik dibandingkan penghapusan data, terutama jika kita perlu menjaga ukuran dataset. Pengisian nilai dapat dilakukan dengan berbagai cara:\n",
        "   - **Mengisi dengan Nilai Konstan:** Misalnya, kita bisa menggantikan *missing values* dengan nilai tertentu seperti 0, atau kata \"Unknown\" untuk tipe data teks.\n",
        "   ```python\n",
        "   df.fillna(0)\n",
        "   df.fillna(\"Unknown\")\n",
        "   ```\n",
        "   - **Mengisi dengan Statistik:** *Missing values* bisa diisi dengan nilai rata-rata (*mean*) atau median--bagi data `numeric`--atau modus--bagi data `string`--dari data lain yang tersedia. Cara ini sering digunakan jika data *missing* terdistribusi secara acak.\n",
        "   ```python\n",
        "   df.fillna(df['Age'].mean())\n",
        "   df.fillna(df['Age'].median())\n",
        "   df.fillna(df['Firstname'].mode())\n",
        "   ```\n",
        "   - **Interpolasi:** Teknik interpolasi menggunakan data di sekitar *missing values* untuk memperkirakan nilai yang hilang. Interpolasi ini sangat tepat untuk dipergunakan jika dataset berisikan data deret waktu atau data kontinu.\n",
        "   ```python\n",
        "   df.interpolate()\n",
        "   ```\n",
        "\n",
        "  **Kapan Melakukan Imputation:** <br>\n",
        "  *Imputation* lebih tepat untuk dilakukan jika kolom atau baris dengan *missing values* mengandung informasi penting, atau jika penghapusan akan menyebabkan hilangnya terlalu banyak data. Namun, metode yang digunakan harus dipilih dengan hati-hati agar tidak mengubah karakteristik asli data.\n",
        "___"
      ],
      "metadata": {
        "id": "-vV8Vf5-2o4M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ilustrasi 2: Missing Values\n",
        "1. Rows with missing values"
      ],
      "metadata": {
        "id": "pSLHcTEIyhtl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating Filter for missing value\n",
        "filter_missing_values = df_titanic['Age'].isnull()\n",
        "\n",
        "# Selecting Rows with missing Age value\n",
        "df_titanic.loc[filter_missing_values, :]"
      ],
      "metadata": {
        "id": "Z7l2KYRGnlCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating filter\n",
        "filter_non_missing_values = ~df_titanic['Age'].isnull()\n",
        "# df_titanic['Age'].notnull()\n",
        "\n",
        "# Selecting rows with Age value not missing\n",
        "df_titanic.loc[filter_non_missing_values, :]"
      ],
      "metadata": {
        "id": "1lQIMZViua8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. How many missing values in each columns"
      ],
      "metadata": {
        "id": "Ki_9sHc3ytt8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lakukan method chaining 'isnull' atau 'isna' lalu 'sum' terhadap df_titanic\n",
        "df_titanic.isnull().sum()"
      ],
      "metadata": {
        "id": "oYa-iUSpy3VC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "___\n",
        "**RESUME**: *Missing Values*\n",
        "\n",
        "Write down your findings here:\n",
        "1. ... abacab ...\n",
        "2. ... abacab ...\n",
        "___"
      ],
      "metadata": {
        "id": "98MIfT3f94Bi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Pengecekan Konsistensi Format Data String"
      ],
      "metadata": {
        "id": "TiA49sgW8Boq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ilustrasi 3: String Formatting\n",
        "1. Kolom `Name` memisahkan `surname` dengan `title` dan `firstname` menggunakan karakter koma"
      ],
      "metadata": {
        "id": "vgiL4Pop2OGA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set pattern yang akan di cek\n",
        "pattern_koma = \",\"\n",
        "\n",
        "# create filter for values with comma\n",
        "filter_comma = df_titanic['Name'].str.contains(pat=pattern_koma, na=False, regex=True)\n",
        "\n",
        "# Select rows using negation of filter_comma\n",
        "df_titanic.loc[~filter_comma, :]"
      ],
      "metadata": {
        "id": "XeEvgbuDxs6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Format penulisan values pada kolom `Name` menggunakan ***Title Case***"
      ],
      "metadata": {
        "id": "mxyPNB5Q2q5z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tentukan pattern yang akan dicari\n",
        "pattern_to_find = \"\\\\b[a-z]+\\\\b\"\n",
        "\n",
        "# Buat filter menggunakan pattern_to_find\n",
        "filter_lower_case = df_titanic['Name'].str.contains(pat=pattern_to_find, regex=True, na=False)\n",
        "\n",
        "# Select Rows menggunakan filter_lower_case\n",
        "df_titanic.loc[filter_lower_case, :]"
      ],
      "metadata": {
        "id": "qxFSLM6p8bOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "___\n",
        "**TECHNICAL NOTES**: `REGEX`\n",
        ">Method `str.contains` di atas menggunakan **`Python Regular Expression Operation`**, biasa diacu sebagai **`regex`**, untuk memeriksa apakah setiap value mengandung string dengan pola tertentu. `regex` biasanya dipergunakan untuk menemukan padanan dari pola tertentu pada data berupa `string`.\n",
        "\n",
        "`Regex` sebetulnya bukan hal yang asing, sebagai ilustrasi, kita pasti pernah melakukan proses pembuatan password, dimana biasanya melibatkan **Validasi** untuk memastikan terpenuhinya beberapa syarat tertentu, seperti:\n",
        "  - Minimal jumlah karakter adalah 8;\n",
        "  - Minimal salah satu karakter tersebut berupa angka;\n",
        "  - Minimal salah satu karakter tersebut berupa huruf kapital; dan\n",
        "  - Minimal salah satu karakter tersebut berupa *special character*.\n",
        "\n",
        "Untuk mempelajari lebih lanjut terkait **`regex`** silahkan cermati dokumentasinya pada tautan [**`berikut`**](https://docs.python.org/3/library/re.html).\n",
        "\n",
        "Beberapa notasi `regex` umum:\n",
        "1. `\"\\\\b\"` atau `r\"\\b\"` ==> notasi bagi **Word Boundary**;\n",
        "2. `\"[a-z]\"` ==> notasi bagi seluruh karakter alfabet lowercase;\n",
        "3. `\"[A-Z]`\" ==> notasi bagi seluruh karakter alfabet uppercase;\n",
        "4. `\"[0-9]\"` ==> notasi bagi seluruh karakter numeric;\n",
        "5. `\"+\"` ==> notasi bagi **kemungkinan** berulangnya pola string sebelumnya;\n",
        "6. `\"*\"` ==> notasi bagi adanya pengulangan pola string sebelumnya;\n",
        "7. `\"^\"` ==> notasi bagi pola di awal dari string;\n",
        "8. `\"$\"` ==> notasi bagi pola di akhir dari string;\n",
        "9. `\"|\"` ==> notasi bagi alternatif pola;\n",
        "10. `\"{x}\"` ==> notasi bagi pengulangan karakter sebanyak x kali;\n",
        "11. `\"{a, b}\"` ==> notasi bagi pengulangan karakter sebanyak antara a hingga b kali;\n",
        "12. `\"{b, }\"` ==> notasi bagi pengulangan karakter setidaknya sebanyak b kali.\n",
        "\n",
        "Berdasarkan daftar notasi di atas, maka arti harfiah dari notasi `regex` `pattern_to_find` di contoh kasus di atas adalah:\n",
        "\n",
        ">\"Pola berupa **rangkaian string** (kata) yang terdiri dari **minimal satu** karakter **alfabet** berformat **lowercase**\".\n",
        "\n",
        "Cara Penulisan notasi `regex`:\n",
        "```python\n",
        "string_pattern = \"\\\\b[a-z]+\\\\b\"     # Sebuah Pattern regex bertipe string\n",
        "raw_string_pattern = r\"\\b[a-z]+\\b\"  # Sebuah pattern regex bertipe raw string\n",
        "```"
      ],
      "metadata": {
        "id": "dseQ4qlqt2UO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cermati kedua **regular expression** di bawah berikut:\n",
        "```python\n",
        "regex_1 = \"\\\\b[A-Z][a-z]+\\\\b\"\n",
        "regex_2 = r\"\\b0817[0-9]+\\b\"\n",
        "```\n",
        "Lalu coba jawab dua soal di bawah ini."
      ],
      "metadata": {
        "id": "CdjtAPXj_vJq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 1. Berikan tanda cek pada string yang sesuai dengan pola pada regex_1:\n",
        "from IPython.display import display\n",
        "import ipywidgets as widgets\n",
        "\n",
        "# Function to check answers\n",
        "def check_answers(correct_answers, options, result_widget):\n",
        "    # Get the current user answers\n",
        "    user_answers = tuple(option.value for option in options)\n",
        "\n",
        "    # Check if user answers match the correct answers\n",
        "    if user_answers == correct_answers:\n",
        "        feedback = \"Jawaban Anda Benar!\"\n",
        "    else:\n",
        "        feedback = \"Jawaban Anda Salah!\"\n",
        "\n",
        "    result_widget.value = feedback\n",
        "\n",
        "correct_answers_1 = (False, False, True, True, True)\n",
        "\n",
        "# Create checkboxes for each option in Question 1\n",
        "option_a_1 = widgets.Checkbox(value=False, description='a. \"AMIR\"')\n",
        "option_b_1 = widgets.Checkbox(value=False, description='b. \"amir\"')\n",
        "option_c_1 = widgets.Checkbox(value=False, description='c. \"Amir Hamzah\"')\n",
        "option_d_1 = widgets.Checkbox(value=False, description='d. \"Amir\"')\n",
        "option_e_1 = widgets.Checkbox(value=False, description='e. \"Am\"')\n",
        "\n",
        "options = [option_a_1, option_b_1, option_c_1, option_d_1, option_e_1]\n",
        "\n",
        "# Output box for feedback\n",
        "result_1 = widgets.Textarea(value=\"\", placeholder='Feedback', description='', disabled=True)\n",
        "\n",
        "# Button to check answers for Question 1\n",
        "check_button_1 = widgets.Button(description=\"Cek Jawaban\")\n",
        "check_button_1.on_click(lambda event: check_answers(correct_answers_1, options, result_1))\n",
        "\n",
        "# Display the interactive form for Question 1\n",
        "display(option_a_1, option_b_1, option_c_1, option_d_1, option_e_1, check_button_1, result_1)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "efo2QbZ2D41P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 2. Berikan tanda cek pada String yang sesuai dengan pola pada regex_2:\n",
        "correct_answers_2 = (True, False, True, False, True)\n",
        "\n",
        "# Create checkboxes for each option in Question 1\n",
        "option_a_2 = widgets.Checkbox(value=False, description=\"a. '08170'\")\n",
        "option_b_2 = widgets.Checkbox(value=False, description='b. \"081902345\"')\n",
        "option_c_2 = widgets.Checkbox(value=False, description='c. \"08170000\"')\n",
        "option_d_2 = widgets.Checkbox(value=False, description='d. \"0817 8787 8988\"')\n",
        "option_e_2 = widgets.Checkbox(value=False, description='e. \"081733\"')\n",
        "\n",
        "options_2 = [option_a_2, option_b_2, option_c_2, option_d_2, option_e_2]\n",
        "\n",
        "# Output box for feedback\n",
        "result_2 = widgets.Textarea(value=\"\", placeholder='Feedback', description='', disabled=True)\n",
        "\n",
        "# Button to check answers for Question 1\n",
        "check_button_2 = widgets.Button(description=\"Cek Jawaban\")\n",
        "check_button_2.on_click(lambda event: check_answers(correct_answers_2, options_2, result_2))\n",
        "\n",
        "# Display the interactive form for Question 1\n",
        "display(option_a_2, option_b_2, option_c_2, option_d_2, option_e_2, check_button_2, result_2)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "hQiMnE4NIaPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "___\n",
        "3. Setiap value pada `Name` terdiri dari `Surname`, `Title`, dan `Firstname`\n",
        "\n",
        "Di bawah berikut dicontohkan cara untuk mengumpulkan informasi terkait berbagai Title yang terdapat pada dataset, dengan menggunakan sebuah user-defined function yang terdapat pada modul functions. Untuk memanfaatkan modul tersebut, silahkan unduh pada link [functions.py](https://github.com/rikrikrahadian/DQLab/blob/main/functions.py), lalu unggah file tersebut ke environment."
      ],
      "metadata": {
        "id": "GqcTtYWC3-yQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import fungsi create_title_pattern ke environment\n",
        "from functions import create_title_pattern"
      ],
      "metadata": {
        "id": "NBQ-kFtyXE7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cek dokumentasi fungsi tersebut\n",
        "help(create_title_pattern)"
      ],
      "metadata": {
        "id": "QmCuA5Zu6bot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Buat title_pattern untuk dipakai mengekstrak Title dari kolom Name\n",
        "title_pattern = create_title_pattern(df_titanic, 'Name')"
      ],
      "metadata": {
        "id": "Ta5hRrHIbg4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cek hasil pemrosesan\n",
        "title_pattern"
      ],
      "metadata": {
        "id": "uQ4Zo-Wk6HRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**TECHNICAL NOTE**: `REGEX`\n",
        "\n",
        "Arti dari notasi `regex`:\n",
        "```python\n",
        "contoh_pattern = r\"\\b(Mr|Mrs)\\b\"\n",
        "```\n",
        "> \"Pola rangkaian string yang mengandung `Mrs` atau `Mr`.\n",
        "___\n",
        "**RESUME**: `Name` Formatting\n",
        "\n",
        "Write your findings down here:\n",
        "1. ---\n",
        "2. ---\n",
        "___"
      ],
      "metadata": {
        "id": "NS9shTSu4-SA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Column `PClass`"
      ],
      "metadata": {
        "id": "vFqw9ut9_ru4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Di bawah berikut akan dilakukan pengecekan terhadap elemen unik pada kolom PClass."
      ],
      "metadata": {
        "id": "_A4DM_HusYWe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cek elemen unik yang dimuat dalam kolom\n",
        "df_titanic['PClass'].unique()"
      ],
      "metadata": {
        "id": "Q2PTsV4K_y6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cek rows dengan penulisan yang tidak seragam\n",
        "df_titanic.loc[df_titanic['PClass']=='*', :]"
      ],
      "metadata": {
        "id": "Y2T5imqTADxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "___\n",
        "**RESUME**: `PClass` Values\n",
        "\n",
        "Write your findings down here:\n",
        "1. ... abacab ...\n",
        "2. ... abacab ...\n",
        "___"
      ],
      "metadata": {
        "id": "PFUJsPetQFQO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EXERCISE 2: *Data Manipulation*\n",
        "\n",
        "Dari pengamatan terhadap data di atas, terdapat beberapa hal yang perlu untuk dilakukan terhadap dataset, antara lain:\n",
        "1. Menyeragamkan Formatting `Name`:\n",
        "  - Penambahan karakter `,` pada rows tanpa koma pada kolom `Name`;\n",
        "  - Penyeragaman penulisan title `Colonel`==`Col`.\n",
        "2. Memiisahkan values pada kolom `Name` menjadi :\n",
        "  - `Title`;\n",
        "  - `Surname`;\n",
        "  - `Firstname`.\n",
        "3. Mengisi missing values pada kolom:\n",
        "  - `Title`; dan\n",
        "  - `Age` berdasarkan `Title`."
      ],
      "metadata": {
        "id": "UrfhMqU337Zu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `Name` Formatting\n",
        "1. Manipulating rows with `Name` value without Comma"
      ],
      "metadata": {
        "id": "uoXlKIkxB5Mb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cek values pada kolom 'Name' yang tidak mengandung \",\"\n",
        "df_titanic.loc[~df_titanic['Name'].str.contains(\",\"), ['Name']]"
      ],
      "metadata": {
        "id": "VGwrYXeJyok5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "___\n",
        "**TECHNICAL NOTE:**\n",
        "\n",
        "Untuk manipulasi penyisipan karakter ini, ketika dilakukan dengan menggunakan software spreadsheet, biasanya kita akan menerapkan algoritma manipulasi seperti berikut:\n",
        "1. Filter dataframe untuk menunjukkan hanya rows dan kolom yang akan dimanipulasi, lalu terhadapnya assign hasil manipulasi;\n",
        "2. Proses manipulasi:\n",
        "  - Ambil seluruh elemen dari kolom yang akan dimanipulasi;\n",
        "  - Filter ke rows spesifik bagi data yang akan dimanipulasi;\n",
        "  - Lakukan manipulasi.\n",
        "___"
      ],
      "metadata": {
        "id": "OJvhx3AYrXGf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_titanic.loc[[457, 1196], ['Name']] = (  # Assign ke kolom 'Name' dengan rows terfilter:\n",
        "    df_titanic['Name']                                               # Values pada kolom 'Name' yang difilter agar\n",
        "    .loc[[457, 1196]]                      # hanya rows berisi strings tidak ber-\",\", lalu\n",
        "    .apply(lambda name: \", \".join(name.split(\" \", maxsplit=1)))      # sisipkan karakter \", \" tepat setelah nama belakangnya.\n",
        ")"
      ],
      "metadata": {
        "id": "I3Z65pSd6ij2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menyisipkan koma ke value  tanpa \", \" pada kolom Name\n",
        "df_titanic.loc[~df_titanic['Name'].str.contains(\",\"), ['Name']] = (  # Assign ke kolom 'Name' dengan rows terfilter:\n",
        "    df_titanic['Name']                                               # Values pada kolom 'Name' yang difilter agar\n",
        "    .loc[~df_titanic['Name'].str.contains(\",\")]                      # hanya rows berisi strings tidak ber-\",\", lalu\n",
        "    .apply(lambda name: \", \".join(name.split(\" \", maxsplit=1)))      # sisipkan karakter \", \" tepat setelah nama belakangnya.\n",
        ")"
      ],
      "metadata": {
        "id": "K1NLthBB4fZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cek hasil manipulasi, seharusnya tidak ada lagi values pada `Name` tanpa \",\"\n",
        "df_titanic.loc[~df_titanic['Name'].str.contains(\",\"), :]"
      ],
      "metadata": {
        "id": "So6SAHfuMIWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_titanic.loc[[457, 1196], :]"
      ],
      "metadata": {
        "id": "dNzEuIkq3NWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "___\n",
        "**TECHNICAL NOTE**\n",
        "\n",
        "> Perhatikan penulisan *script* manipulasi data di atas. `Method chaining` yang biasanya dituliskan dalam 1 baris dapat di*break down* seperti dicontohkan. Pada dasarnya, tidak ada perbedaan pada output yang dihasilkan antara penulisan `method chaining` dalam 1 baris atau terpotong-potong, akan tetapi penulisan terpotong meningkatkan readability dari script, sehingga dianjurkan untuk dilakukan jika `method chaining` yang dipakai cukup panjang.\n",
        "\n",
        "Sebagai ilustrasi, cermati kedua scripts di bawah berikut, cara penulisan mana yang lebih mudah untuk dimengerti??\n",
        "```python\n",
        "# Ilustrasi `method chaining` 1 baris\n",
        "df_titanic['Name'].loc[~filter_comma].apply(lambda name: \", \".join(name.split(\" \", maxsplit=1)))\n",
        "\n",
        "# Ilustrasi `method chaining` terpotong-potong\n",
        "(\n",
        "  df_titanic['Name']\n",
        "  .loc[~filter_comma]\n",
        "  .apply(lambda name: \", \".join(name.split(\" \", maxsplit=1))))\n",
        "```\n",
        "\n",
        "> *Accessor* `loc` sangat berguna dalam proses *data handling*, terutama pada saat melakukan perubahan `value` pada `row` dan `kolom` tertentu.\n",
        "\n",
        "```python\n",
        "# Merubah nilai pada row dan kolom tertentu\n",
        "df.loc[<row_index|row_filter>, <nama_kolom>] = <Nilai pengganti>\n",
        "```\n",
        "___"
      ],
      "metadata": {
        "id": "eGXEzYJ91Vlt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Standardizing title: turn all `Col` into `Colonel`"
      ],
      "metadata": {
        "id": "kInjPXpeMp2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cek rows yang mengandung karakter 'Col` dan 'Colonel'\n",
        "# 1. Set pattern\n",
        "pattern_col_or_colonel = r\"\\b(Col|Colonel)\\b\"\n",
        "\n",
        "# 2. Buat filter\n",
        "filter_col_colonel = (               # Assign ke variabel filter_for_colonel\n",
        "    df_titanic['Name']               # Values pada kolom 'Name' yang\n",
        "    .str                             # diolah menggunakan operasi `string`\n",
        "    .contains(                       # menggunakan method `contains` untuk memverifikasi\n",
        "        pat=pattern_col_or_colonel,  # apakah mengandung pattern_col_or_colonel atau tidak\n",
        "        regex=True,                  # set parameter pattern_col_or_colonel sebagai `regex`\n",
        "        na=False)                    # set argumen na dengan parameter False\n",
        ")\n",
        "\n",
        "# 3. Sortir dataframe menggunakan filter yang sudah dibuat\n",
        "df_titanic.loc[filter_col_colonel, :]"
      ],
      "metadata": {
        "id": "nrFI6GU_QfQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "___\n",
        "**TECHNICAL NOTE**\n",
        "\n",
        "Proses manipulasi pengubahan karakter ini akan menerapkan proses yang sedikit berbeda dengan sebelumnya, ketika dilakukan dengan menggunakan software spreadsheet, biasanya kita akan menerapkan algoritma sebagai berikut:\n",
        "1. Ambil semua elemen dari kolom yang akan di manipulasi, lalu assign kepadanya hasil pengolahan;\n",
        "2. Proses pengolahan:\n",
        "  - Cek satu persatu elemen, apakah mengandung karakter yang akan dirubah atau tidak;\n",
        "  - Lakukan perubahan ke setiap elemen yang mengandung karakter tersebut.\n",
        "___"
      ],
      "metadata": {
        "id": "cokcRbmZu7rZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengganti setiap title `Col' menjadi 'Colonel'\n",
        "df_titanic['Name'] = (    # Assign ke kolom 'Name':\n",
        "    df_titanic['Name']    # Values dari kolom 'Name'\n",
        "    .str                  # yang diolah menggunakan accessor `string`\n",
        "    .replace(             # menggunakan method `replace` untuk mengganti\n",
        "        \"\\\\bCol\\\\b\",      # setiap rangkaian string 'Col'\n",
        "        \"Colonel\",        # dengan rangkaian string 'Colonel'\n",
        "        regex=True))"
      ],
      "metadata": {
        "id": "rm-oh3dW53ld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cek hasil penyeragaman\n",
        "df_titanic.loc[filter_col_colonel, :]"
      ],
      "metadata": {
        "id": "qYmWAbmNO-Hl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Splitting `Name` Values\n",
        "1. Surname from `Name`"
      ],
      "metadata": {
        "id": "q-4_Go9azKkV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cek semua values pada kolom Name\n",
        "df_titanic['Name'].head()"
      ],
      "metadata": {
        "id": "CzRv4HpsgA2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TECHNICAL NOTE**\n",
        "\n",
        "Untuk melakukan manipulasi pemisahan values pada elemen nama ini, maka kita akan melakukan proses dengan algoritma sebagai berikut:\n",
        "1. Buat sebuah dataframe baru berisikan data hasil manipulasi;\n",
        "2. Proses manipulasi:\n",
        "  - Ambil seluruh elemen pada kolom `Name` pada `df_titanic`;\n",
        "  - Lakukan proses `string` menggunakan method split;\n",
        "  - Lakukan penyesuaian nama kolom"
      ],
      "metadata": {
        "id": "NcKC9cLOUmhI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split values pada Name dengan comma\n",
        "df_passenger_names = (                               # Assign ke `df_passenger_names` dataframe yang dihasilkan dari:\n",
        "    df_titanic['Name']                               # Series berisi value kolom `Name` pada df_titanic yang\n",
        "    .str                                             # diolah menggunakan accessor `string` dengan\n",
        "    .split(                                          # menggunakan method `split`\n",
        "        pat=\", \",                                    # untuk memecah value pada series berdasarkan karakter ', '\n",
        "        n=1,                                         # sebanyak 1 kali\n",
        "        expand=True)                                 # dimana hasilnya diexpand menjadi DataFrame tersendiri\n",
        "    .rename(                                         # lalu dilanjut dengan method 'rename'\n",
        "        columns={0:'Surname', 1:'Firstname'})        # untuk merubah nama kolom 0 dan 1 menjadi `Surname` dan `Firstname`\n",
        ")\n",
        "df_passenger_names"
      ],
      "metadata": {
        "id": "oigWVB4pzdms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extracting Title from `Firstname`"
      ],
      "metadata": {
        "id": "hErC1ubMPoe4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "title_pattern"
      ],
      "metadata": {
        "id": "RMB4C89uf52e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TECHNICAL NOTE**\n",
        "\n",
        "Untuk memisahkan Title dari elemen pada kolom `Firstname`, maka kita akan memanfaatkan hasil pengumpulan pattern Title, `title_pattern`, yang sudah kita lakukan sebelumnya. Adapun algoritma pengerjaannya adalah sebagai berikut:\n",
        "1. Buat kolom baru bernama `Title` pada `df_passenger` yang diisikan data hasil manipulasi;\n",
        "2. Proses manipulasi:\n",
        "  - Ambil seluruh elemen pada kolom `Firstname` pada `df_passsenger_name`;\n",
        "  - Lakukan proses `string` dengan method `extract`, menggunakan `title_pattern` sebagai argumen bagi parameter `pat`;"
      ],
      "metadata": {
        "id": "Cr3r6-C7VkGw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extrak Title dari value pada kolom `Firstname` simpan ke kolom baru `Title`\n",
        "df_passenger_names['Title'] = (       # Buat kolom baru bernama `Title` pada `df_passenger_names` untuk diassign:\n",
        "    df_passenger_names['Firstname']   # Series berisi Values dari kolom 'Firstname' pada df_passenger_names yang\n",
        "    .str                              # diolah menggunakan operasi `string` dengan\n",
        "    .extract(                         # menggunakan method `extract` untuk\n",
        "        pat=title_pattern)            # mengambil karakter pada value yang sesuai dengan `title_pattern`\n",
        ")\n",
        "\n",
        "df_passenger_names.head()"
      ],
      "metadata": {
        "id": "-yJg0n_efbNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Omitting Title from `Firstname`'s values"
      ],
      "metadata": {
        "id": "jwl4jCumb6je"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cek Kondisi penulisan `Firstname`\n",
        "df_passenger_names.head()"
      ],
      "metadata": {
        "id": "G8jF7qQppr3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Penghapusan pattern Title dari value pada `Firstname`\n",
        "df_passenger_names['Firstname'] = (      # Assign ke ...... values yang dihasilkan dari:\n",
        "    df_passenger_names['Firstname']      # Olahan dari .....\n",
        "    .str                                 # dengan accessor .....\n",
        "    .replace(                            # menggunakan method .....\n",
        "        f\"{title_pattern}\",              # untuk mengubah .....\n",
        "        \"\",                              # menjadi .....\n",
        "        regex=True)                      # set parameter ..... dengan argumen .....\n",
        "    .str                                 # lalu olah lebih lanjut dengan accessor .....\n",
        "    .strip()                             # menggunakan metode ..... untuk .....\n",
        ")\n",
        "\n",
        "# Cek 5 rows teratas dari hasil olahan\n",
        "df_passenger_names.head()"
      ],
      "metadata": {
        "id": "X0ftAa-GhGrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Joining Two DataFrames"
      ],
      "metadata": {
        "id": "ZpVh9-qmi21U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_titanic.head()"
      ],
      "metadata": {
        "id": "ZmIZ_HpMi-gx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_passenger_names.head()"
      ],
      "metadata": {
        "id": "0VCJUfyvjDwq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Buat list kolom yang diperlukan\n",
        "final_columns_list = ['Title', 'Firstname', 'Surname', 'PClass', 'Age', 'Survived', 'SexCode']\n",
        "\n",
        "# 2. Gabungkan df_titanic, dengan df_passenger_names berdasarkan indeksnya\n",
        "df_titanic_all = (\n",
        "    df_titanic\n",
        "    .join(df_passenger_names, how='left')\n",
        "    .loc[:, final_columns_list]\n",
        ")\n",
        "\n",
        "# Cek Visual hasil penggabungan\n",
        "df_titanic_all.head()"
      ],
      "metadata": {
        "id": "1IBeciYTjJPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "title_pattern"
      ],
      "metadata": {
        "id": "h95oyB0T-mgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_titanic_all.info()"
      ],
      "metadata": {
        "id": "SbkGiLNNNyMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**TECHNICAL NOTE**\n",
        "\n",
        "Modul `pandas` menyediakan beberapa metode untuk menggabungkan beberapa *dataframe*, yang berguna dalam pengolahan data saat informasi yang kita perlukan tersebar di berbagai sumber. Penggabungan data dapat dilakukan berdasarkan berbagai kondisi seperti kesamaan kolom, posisi indeks, atau penyambungan secara vertikal/horizontal. Tiga metode utama yang disediakan oleh `pandas` adalah:\n",
        "\n",
        "a. `pd.DataFrame.merge`<br>\n",
        "[`merge`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html) digunakan untuk menggabungkan dua *dataframe* dengan cara yang mirip dengan operasi `JOIN` pada SQL. Kita dapat menyatukan dua tabel berdasarkan satu atau beberapa kolom yang memiliki nilai kunci yang sama di kedua tabel.\n",
        "\n",
        "**Contoh Penggunaan**:\n",
        "  ```python\n",
        "  df_merged = df1.merge(df2, left_on='key_column', right_on='key_column', how='inner')\n",
        "  ```\n",
        "  - `left_on='key_column'`: Kolom yang menjadi dasar penggabungan di df1 (dataframe kiri).\n",
        "  - `right_on='key_column'`: Kolom yang menjadi dasar penggabungan di df2 (dataframe kanan).\n",
        "  - `how='inner'`: Tipe penggabungan (`'inner'`, `'left'`, `'right'`, `'outer'`).\n",
        "    - `'inner'`: Hanya menggabungkan baris yang memiliki kunci yang sama di kedua *dataframe*.\n",
        "    - `'left'`: Semua baris dari *dataframe* kiri, dan baris yang cocok dari *dataframe* kanan.\n",
        "    - `'right'`: Semua baris dari *dataframe* kanan, dan baris yang cocok dari *dataframe* kiri.\n",
        "    - `'outer'`: Semua baris dari kedua *dataframe*, baik yang cocok maupun yang tidak.\n",
        "\n",
        "  `merge` sangat fleksibel dan memungkinkan penggunaan multi-key joins serta penggabungan dengan kolom yang bernama berbeda.\n",
        "\n",
        "b. `pd.DataFrame.join`<br>\n",
        "[`join`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.join.html) digunakan untuk menggabungkan *dataframe* berdasarkan indeks. Jika kita memiliki dua tabel yang memiliki struktur indeks yang sama, kita dapat menyatukan data berdasarkan indeks tersebut.\n",
        "\n",
        "**Contoh Penggunaan**:\n",
        "```python\n",
        "df_joined = df1.join(df2, how='left')\n",
        "```\n",
        "- `how='left'`: Penggabungan tipe `'left'` berdasarkan indeks yang serupa pada kedua *dataframe*.\n",
        "\n",
        "`join` biasanya lebih sederhana digunakan jika kita sudah memiliki indeks yang tepat pada kedua tabel, dan lebih cocok untuk data dengan relasi berbasis indeks.\n",
        "\n",
        "c. `pd.concat`<br>\n",
        "[`concat`](https://pandas.pydata.org/docs/reference/api/pandas.concat.html) digunakan untuk menggabungkan beberapa *dataframe* secara vertikal (penambahan baris) atau horizontal (penambahan kolom), tanpa membutuhkan kesamaan kunci atau indeks.\n",
        "\n",
        "**Contoh Penggunaan**:\n",
        "```python\n",
        "df_concatenated = pd.concat([df1, df2], axis=0, ignore_index=True)\n",
        "```\n",
        "- `axis=0`: Menyambung baris (*stacking* data secara vertikal).\n",
        "- `axis=1`: Menyambung kolom (*side-by-side* data secara horizontal).\n",
        "- `ignore_index=True`: Mengatur ulang indeks pada *dataframe* yang digabungkan.\n",
        "\n",
        "`concat` memungkinkan kita untuk menggabungkan lebih dari dua *dataframe* sekaligus, dan sering digunakan untuk menggabungkan data yang terpisah dalam beberapa bagian atau jika kita ingin menggabungkan data tanpa syarat kesamaan kunci.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "v9dY3cfyKQq2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Handling Missing Values\n",
        "#### Imputations for Title Values"
      ],
      "metadata": {
        "id": "llT8-CZtmP81"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cek struktur dari dataframe\n",
        "df_titanic_all.info()"
      ],
      "metadata": {
        "id": "wbTJTwKZjou4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cek rows dengan missing Title Value\n",
        "no_title = df_titanic_all.loc[df_titanic_all['Title'].isna(), :]\n",
        "\n",
        "no_title"
      ],
      "metadata": {
        "id": "rA4yw9AAjspb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_titanic_all.loc[[861, 864, 865, 1180], :]"
      ],
      "metadata": {
        "id": "s4LSv86D_guu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengisi missing Title values orang dewasa berjenis kelamin 1 dengan 'Ms'\n",
        "df_titanic_all.loc[[861, 864, 865], ['Title']]='Ms'\n",
        "\n",
        "# Mengisi missing Title values Bagi Anak-anak berjenis kelamin 0\n",
        "df_titanic_all.loc[1180, ['Title']]='Master'\n",
        "\n",
        "# Mengisi missing Title values orang dewasa berjenis kelamin 0\n",
        "df_titanic_all.loc[df_titanic_all['Title'].isna(), ['Title']] = 'Mr'"
      ],
      "metadata": {
        "id": "R92b5nV1j5t8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cek apakah masih ada missing values pada kolom 'Title'\n",
        "df_titanic_all.loc[df_titanic_all['Title'].isna(), :]"
      ],
      "metadata": {
        "id": "XDJ5uuNhsa-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_titanic_all.info()"
      ],
      "metadata": {
        "id": "ENMqn3c4mhqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_titles = df_titanic_all['Title'].unique()\n",
        "all_titles"
      ],
      "metadata": {
        "id": "0SLr-jIcUl1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Age Values"
      ],
      "metadata": {
        "id": "whHQdKm7v2Gg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Kondisi missing value masing-masing Title\n",
        "(df_titanic_all.groupby('Title')\n",
        ".agg({'Age':'count', 'Firstname':'count'})\n",
        ".assign(MissingValues=lambda df: df['Firstname']-df['Age']))"
      ],
      "metadata": {
        "id": "Wg80JV7AadTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Imputation secara Statistik\n",
        "\n",
        "1. Cek Sebaran Data untuk kelompok Title Mr"
      ],
      "metadata": {
        "id": "IdgJwPqZPZP0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Melihat sebaran value Age untuk kelompok ber-Title 'Mr'\n",
        "dataframe = df_titanic_all.loc[df_titanic_all['Title']==\"Mr\", :]\n",
        "print(f\"{'':=^50}\\n\\tMISSING VALUES:\\n\\r\", dataframe.isna().sum())\n",
        "print(f\"{'':=^50}\\n\\tDESCRIPTIVE STATISTICS:\\n\\r\", dataframe['Age'].describe())\n",
        "print(f\"{'':=^50}\\n\\tSEBARAN DATA:\\n\")\n",
        "dataframe['Age'].plot.hist(bins=100)"
      ],
      "metadata": {
        "id": "kS2XOH-DEATJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Isi Missing Value kolom `Age` bagi rows ber `Title`=='Mr' dengan median bagi `Age` di kelompok 'Mr'"
      ],
      "metadata": {
        "id": "nOxkVhEaWWNL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengisi missing Age value Untuk Kelompok bertitel Mr\n",
        "df_titanic_all.loc[\n",
        "    (df_titanic_all['Title']=='Mr') &\n",
        "    (df_titanic_all['Age'].isna()),\n",
        "    ['Age']\n",
        "] = (df_titanic_all\n",
        "     .loc[\n",
        "         df_titanic_all['Title']=='Mr',\n",
        "         :\n",
        "     ]['Age']\n",
        "     .median())"
      ],
      "metadata": {
        "id": "XFzIC0ryqPBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Melakukan imputation menggunakan users' defined function"
      ],
      "metadata": {
        "id": "zvhlY3xXDh4F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import fungsi handling_missing_value dari modul functions\n",
        "from functions import fill_missing_value, explore_column_pattern"
      ],
      "metadata": {
        "id": "fYGFB1J9zTU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "help(explore_column_pattern)"
      ],
      "metadata": {
        "id": "GKKCVtozrcy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "help(fill_missing_value)"
      ],
      "metadata": {
        "id": "ORdwcAY8T0DK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling missing value pada Age untuk Title=='Mrs'\n",
        "explore_column_pattern(df_titanic_all, \"Title\", \"Age\", 'Mrs', 100)\n",
        "fill_missing_value(df_titanic_all, \"Title\", \"Mrs\", \"Age\")"
      ],
      "metadata": {
        "id": "Hqu-tcfJZzkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling missing value pada Age untuk Title=='Miss'\n",
        "explore_column_pattern(df_titanic_all, \"Title\", \"Age\", 'Miss', 100)"
      ],
      "metadata": {
        "id": "d6_Ik4WfsMak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_titanic_all.loc[(df_titanic_all['Title']=='Miss') & (df_titanic_all['Age'].isna()), ['Age']] = df_titanic_all.loc[df_titanic_all['Title']=='Miss', :]['Age'].median()"
      ],
      "metadata": {
        "id": "6nSmrViHvBcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_titanic_all[(df_titanic_all['Title']=='Miss') & (df_titanic_all['Age'].isna())]"
      ],
      "metadata": {
        "id": "-tcZOeamtBPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Imputation menggunakan accessor `.loc`"
      ],
      "metadata": {
        "id": "lU-bUduDBy2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling missing value pada Age untuk Title=='Jonkheer'\n",
        "(df_titanic_all\n",
        " .loc[\n",
        "     df_titanic_all['Title']=='Jonkheer',\n",
        "      ['Age']]) = (df_titanic_all\n",
        "                   .loc[\n",
        "                       df_titanic_all['Title']=='Mr',\n",
        "                        ['Age']]['Age'].mean())"
      ],
      "metadata": {
        "id": "u-W4TNbahhfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling missing value pada Age untuk Title=='Madame' & 'Mlle'\n",
        "(df_titanic_all\n",
        " .loc[\n",
        "     df_titanic_all['Title']\n",
        "     .isin(['Madame', 'Mlle']),\n",
        "      ['Age']]) = (df_titanic_all\n",
        "                   .loc[\n",
        "                       df_titanic_all['Title']\n",
        "                       .isin(['Mrs']),\n",
        "                        ['Age']]['Age'].mean())"
      ],
      "metadata": {
        "id": "kcwRDeq3f8se"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(df_titanic_all\n",
        " .loc[\n",
        "     df_titanic_all['Title']\n",
        "     .isin(['Dr', 'Rev']),\n",
        "      ['Age']]) = (df_titanic_all\n",
        "                   .loc[\n",
        "                       df_titanic_all['Title']\n",
        "                       .isin(['Mr']),\n",
        "                        ['Age']]['Age'].mean())"
      ],
      "metadata": {
        "id": "4DorONZrFTTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_titanic_all.info()"
      ],
      "metadata": {
        "id": "O3-gV0xs_ufS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Menghitung Survival Rate Penumpang MS. Titanic"
      ],
      "metadata": {
        "id": "Dz7Pf2a_xDEF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Total Survival Rate\n",
        "(df_titanic_all\n",
        " .agg({'Survived':'sum'}))/(df_titanic_all.agg({'Survived':'count'}))*100"
      ],
      "metadata": {
        "id": "1Y3K4Us_bncg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Survival Rate by SexCode\n",
        "(df_titanic_all.groupby('SexCode')\n",
        ".agg({'Survived':['sum', 'count']})\n",
        ".pipe(lambda df: df.set_axis(['Survivors', 'Passengers'], axis=1))\n",
        ".assign(SurvivalRate= lambda df: round(df['Survivors']/df['Passengers']*100, 2))\n",
        ")"
      ],
      "metadata": {
        "id": "bNvVqRKAvS7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Survival Rate by SexCode, PClass\n",
        "(df_titanic_all.groupby(['SexCode', 'PClass'])\n",
        ".agg({'Survived':['sum', 'count']})\n",
        ".pipe(lambda df: df.set_axis(['Survivors', 'Passengers'], axis=1))\n",
        ".assign(SurvivalRate= lambda df: round(df['Survivors']/df['Passengers']*100, 2)))"
      ],
      "metadata": {
        "id": "pdEYa445v6K6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Survival Rate by SexCode, Title, PClass\n",
        "(df_titanic_all.groupby(['SexCode', 'Title', 'PClass'])\n",
        ".agg({'Survived':['sum', 'count']})\n",
        ".pipe(lambda df: df.set_axis(['Survivors', 'Passengers'], axis=1))\n",
        ".assign(SurvivalRate= lambda df: round(df['Survivors']/df['Passengers']*100, 2)))"
      ],
      "metadata": {
        "id": "ja3wJBmF6p7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Memperoleh informasi apakah seseorang itu travelling sendiri atau bersama keluarga\n",
        "# Kriteria seseorang Solo VS With Family adalah travelling lebih dari 1 pada kelas yang sama\n",
        "family_or_solo_passengers = (\n",
        "    df_titanic_all.groupby(['PClass', 'Surname'])\n",
        "     .agg({'Firstname':'count'})\n",
        "     .rename(columns={'Firstname':'Travelling'})\n",
        "     .assign(Travelling=lambda df: df['Travelling'].apply(lambda x: \"Solo\" if x==1 else 'With Family'))\n",
        "     .reset_index()\n",
        ")"
      ],
      "metadata": {
        "id": "yUVqvA6Jwfer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "family_or_solo_passengers"
      ],
      "metadata": {
        "id": "vjnv9TkaB6CC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gabungkan hasil olahan di atas dengan dataframe original\n",
        "(df_titanic_all\n",
        " .merge(\n",
        "     family_or_solo_passengers,\n",
        "     left_on=['PClass', 'Surname'],\n",
        "     right_on=['PClass', 'Surname'],\n",
        "     how='left')\n",
        " .groupby(['Travelling', 'SexCode'])\n",
        " .agg({'Survived':['count', 'sum']})\n",
        " .pipe(lambda df: df.set_axis(['Passengers', 'Survivors'], axis=1))\n",
        " .assign(SurvivalRate=lambda df: round(df['Survivors']/df['Passengers']*100, 2))\n",
        ")"
      ],
      "metadata": {
        "id": "grkNwq1N15R7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_titanic_all.loc[df_titanic_all['Surname']=='Allen']"
      ],
      "metadata": {
        "id": "FRCP5n3fAqIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "___"
      ],
      "metadata": {
        "id": "SH2Y5Z_2BDV4"
      }
    }
  ]
}